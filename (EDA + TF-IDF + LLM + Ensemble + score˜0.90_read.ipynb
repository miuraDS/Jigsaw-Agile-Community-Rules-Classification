{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":94635,"databundleVersionId":13121456,"sourceType":"competition"},{"sourceId":13338032,"sourceType":"datasetVersion","datasetId":8457579},{"sourceId":590468,"sourceType":"modelInstanceVersion","modelInstanceId":441632,"modelId":458182}],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\nimport re\nfrom wordcloud import WordCloud\n\n# Load data\nprint(\"Loading data...\")\ntrain_df = pd.read_csv(\"/kaggle/input/jigsaw-agile-community-rules/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/jigsaw-agile-community-rules/test.csv\")\n\nprint(\"=\"*80)\nprint(\"DATASET OVERVIEW\")\nprint(\"=\"*80)\nprint(f\"Training samples: {len(train_df)}\")\nprint(f\"Test samples: {len(test_df)}\")\nprint(f\"\\nTrain columns: {train_df.columns.tolist()}\")\nprint(f\"Test columns: {test_df.columns.tolist()}\")\n\n# Class distribution\nprint(\"\\n\" + \"=\"*80)\nprint(\"CLASS DISTRIBUTION\")\nprint(\"=\"*80)\nprint(train_df['rule_violation'].value_counts())\nprint(f\"\\nViolation rate: {train_df['rule_violation'].mean()*100:.2f}%\")\nprint(f\"Balance ratio: {train_df['rule_violation'].value_counts()[1] / train_df['rule_violation'].value_counts()[0]:.2f}\")\n\n# Text length analysis\nprint(\"\\n\" + \"=\"*80)\nprint(\"TEXT LENGTH ANALYSIS\")\nprint(\"=\"*80)\n\ntrain_df['text_length'] = train_df['body'].astype(str).str.len()\ntrain_df['word_count'] = train_df['body'].astype(str).str.split().str.len()\n\nfor label in [0, 1]:\n    subset = train_df[train_df['rule_violation'] == label]\n    print(f\"\\nClass {label} ({'VIOLATION' if label == 1 else 'CLEAN'}):\")\n    print(f\"  Avg text length: {subset['text_length'].mean():.1f}\")\n    print(f\"  Avg word count: {subset['word_count'].mean():.1f}\")\n    print(f\"  Median text length: {subset['text_length'].median():.1f}\")\n    print(f\"  Max text length: {subset['text_length'].max()}\")\n\n# Rule distribution\nprint(\"\\n\" + \"=\"*80)\nprint(\"RULE DISTRIBUTION\")\nprint(\"=\"*80)\nprint(\"\\nTop 5 rules in training data:\")\nprint(train_df['rule'].value_counts().head())\n\nprint(\"\\nRules in test data:\")\nprint(test_df['rule'].value_counts())\n\n# Subreddit distribution\nprint(\"\\n\" + \"=\"*80)\nprint(\"SUBREDDIT DISTRIBUTION\")\nprint(\"=\"*80)\nprint(\"\\nTop 10 subreddits in training:\")\nprint(train_df['subreddit'].value_counts().head(10))\n\nprint(\"\\nSubreddits in test:\")\nprint(test_df['subreddit'].value_counts())\n\n# URL analysis\nprint(\"\\n\" + \"=\"*80)\nprint(\"URL ANALYSIS\")\nprint(\"=\"*80)\n\ntrain_df['has_url'] = train_df['body'].astype(str).str.contains(r'http|www\\.', case=False, na=False)\ntest_df['has_url'] = test_df['body'].astype(str).str.contains(r'http|www\\.', case=False, na=False)\n\nprint(f\"\\nTrain - URLs by class:\")\nfor label in [0, 1]:\n    pct = train_df[train_df['rule_violation'] == label]['has_url'].mean() * 100\n    print(f\"  Class {label}: {pct:.1f}% have URLs\")\n\nprint(f\"\\nTest - URLs: {test_df['has_url'].mean()*100:.1f}%\")\n\n# Special characters analysis\nprint(\"\\n\" + \"=\"*80)\nprint(\"SPECIAL CHARACTERS ANALYSIS\")\nprint(\"=\"*80)\n\n# Define regex patterns outside f-strings\nquestion_pattern = r'\\?'\ndigit_pattern = r'\\d'\n\nfor label in [0, 1]:\n    subset = train_df[train_df['rule_violation'] == label]['body'].astype(str)\n    exclaim_avg = subset.str.count('!').mean()\n    question_avg = subset.str.count(question_pattern).mean()\n    digit_avg = subset.str.count(digit_pattern).mean()\n    caps_avg = subset.apply(lambda x: sum(c.isupper() for c in x) / max(len(x), 1)).mean()\n    \n    print(f\"\\nClass {label}:\")\n    print(f\"  Avg exclamation marks: {exclaim_avg:.2f}\")\n    print(f\"  Avg question marks: {question_avg:.2f}\")\n    print(f\"  Avg numbers: {digit_avg:.2f}\")\n    print(f\"  Avg caps ratio: {caps_avg:.3f}\")\n\ntest_texts = test_df['body'].astype(str)\ntest_exclaim = test_texts.str.count('!').mean()\ntest_question = test_texts.str.count(question_pattern).mean()\ntest_caps = test_texts.apply(lambda x: sum(c.isupper() for c in x) / max(len(x), 1)).mean()\n\nprint(f\"\\nTest data:\")\nprint(f\"  Avg exclamation marks: {test_exclaim:.2f}\")\nprint(f\"  Avg question marks: {test_question:.2f}\")\nprint(f\"  Avg caps ratio: {test_caps:.3f}\")\n\n# Keyword analysis\nprint(\"\\n\" + \"=\"*80)\nprint(\"SPAM KEYWORD ANALYSIS\")\nprint(\"=\"*80)\n\nspam_keywords = ['free', 'click', 'buy', 'discount', 'win', 'prize', 'earn', 'money', 'cash', 'bonus']\n\nprint(\"\\nKeyword frequency in VIOLATIONS:\")\nfor kw in spam_keywords:\n    count = train_df[train_df['rule_violation'] == 1]['body'].astype(str).str.contains(kw, case=False).sum()\n    pct = count / len(train_df[train_df['rule_violation'] == 1]) * 100\n    print(f\"  '{kw}': {count} ({pct:.1f}%)\")\n\nprint(\"\\nKeyword frequency in CLEAN:\")\nfor kw in spam_keywords:\n    count = train_df[train_df['rule_violation'] == 0]['body'].astype(str).str.contains(kw, case=False).sum()\n    pct = count / len(train_df[train_df['rule_violation'] == 0]) * 100\n    print(f\"  '{kw}': {count} ({pct:.1f}%)\")\n\nprint(\"\\nKeyword frequency in TEST:\")\nfor kw in spam_keywords:\n    count = test_df['body'].astype(str).str.contains(kw, case=False).sum()\n    print(f\"  '{kw}': {count} / {len(test_df)}\")\n\n# Sample texts\nprint(\"\\n\" + \"=\"*80)\nprint(\"SAMPLE VIOLATIONS (First 3)\")\nprint(\"=\"*80)\nfor i, row in train_df[train_df['rule_violation'] == 1].head(3).iterrows():\n    print(f\"\\n{i+1}. [{row['subreddit']}] {row['body'][:200]}...\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"SAMPLE CLEAN (First 3)\")\nprint(\"=\"*80)\nfor i, row in train_df[train_df['rule_violation'] == 0].head(3).iterrows():\n    print(f\"\\n{i+1}. [{row['subreddit']}] {row['body'][:200]}...\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"ALL TEST SAMPLES\")\nprint(\"=\"*80)\nfor i, row in test_df.iterrows():\n    print(f\"\\n{i+1}. [{row['subreddit']}] {row['body'][:150]}...\")\n\n# Visualization\nprint(\"\\n\" + \"=\"*80)\nprint(\"GENERATING VISUALIZATIONS...\")\nprint(\"=\"*80)\n\nfig, axes = plt.subplots(2, 3, figsize=(18, 12))\n\n# 1. Class distribution\naxes[0, 0].bar(['Clean', 'Violation'], train_df['rule_violation'].value_counts().sort_index())\naxes[0, 0].set_title('Class Distribution', fontsize=14, fontweight='bold')\naxes[0, 0].set_ylabel('Count')\n\n# 2. Text length by class\ntrain_df.boxplot(column='text_length', by='rule_violation', ax=axes[0, 1])\naxes[0, 1].set_title('Text Length Distribution by Class', fontsize=14, fontweight='bold')\naxes[0, 1].set_xlabel('Class (0=Clean, 1=Violation)')\naxes[0, 1].set_ylabel('Text Length')\n\n# 3. Word count by class\ntrain_df.boxplot(column='word_count', by='rule_violation', ax=axes[0, 2])\naxes[0, 2].set_title('Word Count Distribution by Class', fontsize=14, fontweight='bold')\naxes[0, 2].set_xlabel('Class (0=Clean, 1=Violation)')\naxes[0, 2].set_ylabel('Word Count')\n\n# 4. URL presence\nurl_data = train_df.groupby('rule_violation')['has_url'].mean() * 100\naxes[1, 0].bar(['Clean', 'Violation'], url_data)\naxes[1, 0].set_title('URL Presence by Class (%)', fontsize=14, fontweight='bold')\naxes[1, 0].set_ylabel('Percentage')\n\n# 5. Top subreddits\ntop_subs = train_df['subreddit'].value_counts().head(10)\naxes[1, 1].barh(range(len(top_subs)), top_subs.values)\naxes[1, 1].set_yticks(range(len(top_subs)))\naxes[1, 1].set_yticklabels(top_subs.index)\naxes[1, 1].set_title('Top 10 Subreddits', fontsize=14, fontweight='bold')\naxes[1, 1].set_xlabel('Count')\n\n# 6. Top rules\ntop_rules = train_df['rule'].value_counts().head(5)\naxes[1, 2].barh(range(len(top_rules)), top_rules.values)\naxes[1, 2].set_yticks(range(len(top_rules)))\naxes[1, 2].set_yticklabels([r[:30] + '...' for r in top_rules.index])\naxes[1, 2].set_title('Top 5 Rules', fontsize=14, fontweight='bold')\naxes[1, 2].set_xlabel('Count')\n\nplt.tight_layout()\nplt.savefig('data_analysis.png', dpi=150, bbox_inches='tight')\nprint(\"Saved: data_analysis.png\")\n\n# Train vs Test comparison\nprint(\"\\n\" + \"=\"*80)\nprint(\"TRAIN VS TEST DISTRIBUTION COMPARISON\")\nprint(\"=\"*80)\n\nprint(\"\\nFeature comparison:\")\nprint(f\"{'Feature':<20} {'Train (Violation)':<20} {'Train (Clean)':<20} {'Test':<20}\")\nprint(\"-\" * 80)\n\nfeatures = {\n    'Avg text length': (\n        train_df[train_df['rule_violation']==1]['text_length'].mean(),\n        train_df[train_df['rule_violation']==0]['text_length'].mean(),\n        test_df['body'].astype(str).str.len().mean()\n    ),\n    'Has URL (%)': (\n        train_df[train_df['rule_violation']==1]['has_url'].mean()*100,\n        train_df[train_df['rule_violation']==0]['has_url'].mean()*100,\n        test_df['has_url'].mean()*100\n    ),\n    'Avg ! count': (\n        train_df[train_df['rule_violation']==1]['body'].astype(str).str.count('!').mean(),\n        train_df[train_df['rule_violation']==0]['body'].astype(str).str.count('!').mean(),\n        test_df['body'].astype(str).str.count('!').mean()\n    )\n}\n\nfor feat_name, (viol, clean, test_val) in features.items():\n    print(f\"{feat_name:<20} {viol:<20.2f} {clean:<20.2f} {test_val:<20.2f}\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"KEY INSIGHTS & RECOMMENDATIONS\")\nprint(\"=\"*80)\n\n# Calculate similarity to each class\ntest_avg_len = test_df['body'].astype(str).str.len().mean()\nviol_avg_len = train_df[train_df['rule_violation']==1]['text_length'].mean()\nclean_avg_len = train_df[train_df['rule_violation']==0]['text_length'].mean()\n\ntest_url_pct = test_df['has_url'].mean()\nviol_url_pct = train_df[train_df['rule_violation']==1]['has_url'].mean()\nclean_url_pct = train_df[train_df['rule_violation']==0]['has_url'].mean()\n\nprint(\"\\n1. Distribution Analysis:\")\nprint(f\"   - Test data is closer to VIOLATION class in URL presence\")\nprint(f\"   - Test samples: {len(test_df)} (very small - high variance risk)\")\n\nprint(\"\\n2. Class Balance:\")\nprint(f\"   - Train is balanced ({train_df['rule_violation'].mean()*100:.1f}% violations)\")\nprint(f\"   - Good for training, no major class imbalance issues\")\n\nprint(\"\\n3. Recommended Strategy:\")\nprint(\"   - Focus on spam-specific features (URLs, keywords, special chars)\")\nprint(\"   - Use TF-IDF with character n-grams for spam patterns\")\nprint(\"   - Classical ML may outperform deep learning (small, specific test set)\")\nprint(\"   - Cross-validation is critical (test set too small for reliable validation)\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"ANALYSIS COMPLETE\")\nprint(\"=\"*80)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-15T06:57:47.166069Z","iopub.execute_input":"2025-10-15T06:57:47.16679Z","iopub.status.idle":"2025-10-15T06:57:50.59334Z","shell.execute_reply.started":"2025-10-15T06:57:47.16676Z","shell.execute_reply":"2025-10-15T06:57:50.592603Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nJigsaw Competition - HIGH PERFORMANCE + STABLE Pipeline\nTarget: 0.90+ accuracy with deterministic behavior\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, get_linear_schedule_with_warmup\nfrom peft import LoraConfig, get_peft_model\nfrom datasets import Dataset\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.svm import SVC\nimport torch\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nimport warnings\nimport random\nimport os\nwarnings.filterwarnings('ignore')\n\n# =====================================================\n# DETERMINISTIC SETUP\n# =====================================================\n\ndef set_seed(seed=42):\n    \"\"\"Make everything deterministic\"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n# =====================================================\n# CONFIG - OPTIMIZED FOR PERFORMANCE\n# =====================================================\n\nclass Config:\n    MODEL_PATH = \"/kaggle/input/qwen2-5-transformers-0-5b-v1-tar\"\n    OUTPUT_DIR = \"./qwen_finetuned_high_perf\"\n    \n    # Training - OPTIMIZED\n    N_EPOCHS = 2  # More epochs for better learning\n    BATCH_SIZE = 2  # Larger batch\n    GRADIENT_ACCUMULATION = 8  # Adjusted for batch size\n    LEARNING_RATE = 3e-4  # INCREASED - sweet spot for LoRA\n    MAX_LENGTH = 512\n    WARMUP_STEPS = 100  # More warmup\n    MAX_GRAD_NORM = 1.0  # RESTORED - less aggressive clipping\n    \n    # LoRA - OPTIMIZED\n    LORA_R = 32  # DOUBLED - more capacity\n    LORA_ALPHA = 64  # DOUBLED\n    LORA_DROPOUT = 0.1  # RESTORED\n    \n    # TTA - AGGRESSIVE\n    N_TTA = 7  # More augmentations\n    \n    # Ensemble - POWERFUL\n    ENSEMBLE_WEIGHT_LLM = 0.7  # Balance with classical\n    ENSEMBLE_WEIGHT_CLASSICAL = 0.3\n    \n    SEED = 42\n\n# =====================================================\n# ENHANCED DATA PREPARATION\n# =====================================================\n\ndef prepare_training_data_enhanced():\n    print(\"=\" * 70)\n    print(\"PREPARING ENHANCED TRAINING DATA\")\n    print(\"=\" * 70)\n    \n    train_df = pd.read_csv(\"/kaggle/input/jigsaw-agile-community-rules/train.csv\")\n    test_df = pd.read_csv(\"/kaggle/input/jigsaw-agile-community-rules/test.csv\")\n    \n    all_data = []\n    \n    # DETERMINISTIC but use ALL combinations\n    for idx, row in train_df.iterrows():\n        # Use BOTH positive and negative examples for better coverage\n        for pos_idx in [1, 2]:\n            for neg_idx in [1, 2]:\n                all_data.append({\n                    'subreddit': row['subreddit'],\n                    'rule': row['rule'],\n                    'body': row['body'],\n                    'pos_ex': row[f'positive_example_{pos_idx}'],\n                    'neg_ex': row[f'negative_example_{neg_idx}'],\n                    'label': int(row['rule_violation'])\n                })\n    \n    # Add test data (pseudo-labels)\n    for idx, row in test_df.iterrows():\n        for i in [1, 2]:\n            all_data.append({\n                'subreddit': row['subreddit'],\n                'rule': row['rule'],\n                'body': row[f'positive_example_{i}'],\n                'pos_ex': row[f'positive_example_{3-i}'],\n                'neg_ex': row['negative_example_1'] if idx % 2 == 0 else row['negative_example_2'],\n                'label': 1\n            })\n        \n        for i in [1, 2]:\n            all_data.append({\n                'subreddit': row['subreddit'],\n                'rule': row['rule'],\n                'body': row[f'negative_example_{i}'],\n                'pos_ex': row['positive_example_1'] if idx % 2 == 0 else row['positive_example_2'],\n                'neg_ex': row[f'negative_example_{3-i}'],\n                'label': 0\n            })\n    \n    df = pd.DataFrame(all_data).drop_duplicates(subset=['body']).reset_index(drop=True)\n    \n    # Balance dataset\n    violations = df[df['label'] == 1]\n    non_violations = df[df['label'] == 0]\n    \n    min_samples = min(len(violations), len(non_violations))\n    \n    violations_balanced = violations.sample(n=min_samples, random_state=Config.SEED)\n    non_violations_balanced = non_violations.sample(n=min_samples, random_state=Config.SEED)\n    \n    df = pd.concat([violations_balanced, non_violations_balanced]).sample(frac=1, random_state=Config.SEED).reset_index(drop=True)\n    \n    print(f\"Total samples: {len(df)}\")\n    print(f\"  Violations: {df['label'].sum()}\")\n    print(f\"  Non-violations: {len(df) - df['label'].sum()}\")\n    print(f\"  Balance ratio: {df['label'].mean():.2f}\")\n    \n    return df\n\n\n# =====================================================\n# TOKENIZATION\n# =====================================================\n\ndef create_prompt_and_tokenize(row, tokenizer):\n    messages = [\n        {'role': 'system', 'content': 'You are an expert content moderator. Analyze if the comment violates the rule. Answer only Yes or No.'},\n        {'role': 'user', 'content': f\"\"\"Subreddit: r/{row['subreddit']}\n\nRule: {row['rule']}\n\nExample of VIOLATION:\n{row['pos_ex']}\n\nExample of NON-violation:\n{row['neg_ex']}\n\nComment to analyze:\n{row['body']}\n\nDoes this comment violate the rule?\"\"\"},\n        {'role': 'assistant', 'content': 'Yes' if row['label'] == 1 else 'No'}\n    ]\n    \n    full_text = tokenizer.apply_chat_template(messages, tokenize=False)\n    \n    full_tokens = tokenizer(\n        full_text,\n        truncation=True,\n        max_length=Config.MAX_LENGTH,\n        padding='max_length'\n    )\n    \n    assistant_response = 'Yes' if row['label'] == 1 else 'No'\n    response_tokens = tokenizer.encode(assistant_response, add_special_tokens=False)\n    \n    labels = full_tokens['input_ids'].copy()\n    response_len = len(response_tokens)\n    \n    for i in range(len(labels) - response_len + 1):\n        if labels[i:i+response_len] == response_tokens:\n            for j in range(i):\n                labels[j] = -100\n            for j in range(i+response_len, len(labels)):\n                labels[j] = -100\n            break\n    else:\n        labels = [-100] * len(labels)\n    \n    return {\n        'input_ids': full_tokens['input_ids'],\n        'attention_mask': full_tokens['attention_mask'],\n        'labels': labels\n    }\n\n\ndef prepare_dataset(df, tokenizer):\n    print(\"\\nTokenizing dataset...\")\n    data_list = []\n    for _, row in tqdm(df.iterrows(), total=len(df)):\n        data_list.append(create_prompt_and_tokenize(row, tokenizer))\n    return Dataset.from_list(data_list)\n\n\n# =====================================================\n# TRAINING WITH STABILITY\n# =====================================================\n\ndef train_model(model, train_loader, optimizer, scheduler, device, scaler):\n    model.train()\n    total_loss = 0\n    valid_steps = 0\n    optimizer.zero_grad()\n    \n    pbar = tqdm(train_loader, desc=\"Training\")\n    \n    for step, batch in enumerate(pbar):\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n        \n        with torch.cuda.amp.autocast():\n            outputs = model(\n                input_ids=input_ids,\n                attention_mask=attention_mask,\n                labels=labels\n            )\n            loss = outputs.loss / Config.GRADIENT_ACCUMULATION\n        \n        if torch.isnan(loss):\n            print(f\"\\n‚ö†Ô∏è  NaN at step {step}, skipping...\")\n            continue\n        \n        scaler.scale(loss).backward()\n        \n        total_loss += loss.item() * Config.GRADIENT_ACCUMULATION\n        valid_steps += 1\n        \n        if (step + 1) % Config.GRADIENT_ACCUMULATION == 0:\n            scaler.unscale_(optimizer)\n            torch.nn.utils.clip_grad_norm_(model.parameters(), Config.MAX_GRAD_NORM)\n            scaler.step(optimizer)\n            scaler.update()\n            scheduler.step()\n            optimizer.zero_grad()\n            \n            if valid_steps > 0:\n                pbar.set_postfix({'loss': f\"{total_loss / valid_steps:.4f}\"})\n    \n    return total_loss / max(valid_steps, 1)\n\n\n# =====================================================\n# FINE-TUNING\n# =====================================================\n\ndef finetune_model():\n    print(\"\\n\" + \"=\" * 70)\n    print(\"STEP 1: FINE-TUNING (HIGH PERFORMANCE)\")\n    print(\"=\" * 70)\n    \n    set_seed(Config.SEED)\n    \n    tokenizer = AutoTokenizer.from_pretrained(\n        Config.MODEL_PATH,\n        trust_remote_code=True,\n        local_files_only=True\n    )\n    if tokenizer.pad_token is None:\n        tokenizer.pad_token = tokenizer.eos_token\n    \n    model = AutoModelForCausalLM.from_pretrained(\n        Config.MODEL_PATH,\n        torch_dtype=torch.float16,\n        device_map=\"auto\",\n        trust_remote_code=True,\n        local_files_only=True\n    )\n    \n    model.gradient_checkpointing_enable()\n    \n    print(\"\\nApplying Enhanced LoRA...\")\n    lora_config = LoraConfig(\n        r=Config.LORA_R,\n        lora_alpha=Config.LORA_ALPHA,\n        lora_dropout=Config.LORA_DROPOUT,\n        bias=\"none\",\n        task_type=\"CAUSAL_LM\",\n        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n    )\n    \n    model = get_peft_model(model, lora_config)\n    model.print_trainable_parameters()\n    \n    train_df = prepare_training_data_enhanced()\n    train_dataset = prepare_dataset(train_df, tokenizer)\n    \n    def collate_fn(batch):\n        return {\n            'input_ids': torch.tensor([item['input_ids'] for item in batch], dtype=torch.long),\n            'attention_mask': torch.tensor([item['attention_mask'] for item in batch], dtype=torch.long),\n            'labels': torch.tensor([item['labels'] for item in batch], dtype=torch.long)\n        }\n    \n    def seed_worker(worker_id):\n        np.random.seed(Config.SEED + worker_id)\n        random.seed(Config.SEED + worker_id)\n    \n    g = torch.Generator()\n    g.manual_seed(Config.SEED)\n    \n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=Config.BATCH_SIZE,\n        shuffle=True,\n        collate_fn=collate_fn,\n        num_workers=0,\n        pin_memory=True,\n        generator=g,\n        worker_init_fn=seed_worker\n    )\n    \n    optimizer = torch.optim.AdamW(\n        model.parameters(), \n        lr=Config.LEARNING_RATE,\n        eps=1e-8,\n        weight_decay=0.01,\n        betas=(0.9, 0.999)\n    )\n    \n    total_steps = len(train_loader) * Config.N_EPOCHS // Config.GRADIENT_ACCUMULATION\n    scheduler = get_linear_schedule_with_warmup(\n        optimizer,\n        num_warmup_steps=Config.WARMUP_STEPS,\n        num_training_steps=total_steps\n    )\n    \n    device = next(model.parameters()).device\n    scaler = torch.cuda.amp.GradScaler()\n    \n    training_successful = True\n    best_loss = float('inf')\n    \n    for epoch in range(Config.N_EPOCHS):\n        print(f\"\\nEpoch {epoch + 1}/{Config.N_EPOCHS}\")\n        avg_loss = train_model(model, train_loader, optimizer, scheduler, device, scaler)\n        print(f\"Average loss: {avg_loss:.4f}\")\n        \n        if np.isnan(avg_loss):\n            print(\"‚ùå TRAINING FAILED: Loss is NaN!\")\n            training_successful = False\n            break\n        \n        if avg_loss < best_loss:\n            best_loss = avg_loss\n            print(f\"‚úÖ New best loss: {best_loss:.4f}\")\n        \n        if avg_loss < 0.5:\n            print(\"üéØ Excellent! Model is learning very well!\")\n        elif avg_loss < 0.8:\n            print(\"‚úÖ Good! Model is learning!\")\n    \n    if training_successful:\n        model.save_pretrained(Config.OUTPUT_DIR)\n        tokenizer.save_pretrained(Config.OUTPUT_DIR)\n        print(f\"‚úÖ Model saved to: {Config.OUTPUT_DIR}\")\n    else:\n        print(\"‚ö†Ô∏è  Using base model\")\n    \n    return Config.OUTPUT_DIR if training_successful else Config.MODEL_PATH, tokenizer, training_successful\n\n\n# =====================================================\n# AGGRESSIVE TTA\n# =====================================================\n\ndef inference_with_aggressive_tta(model_path, tokenizer, use_base=False):\n    print(\"\\n\" + \"=\" * 70)\n    print(\"STEP 2: AGGRESSIVE TEST-TIME AUGMENTATION\")\n    print(\"=\" * 70)\n    \n    set_seed(Config.SEED)\n    \n    try:\n        if use_base:\n            model_path = Config.MODEL_PATH\n        \n        model = AutoModelForCausalLM.from_pretrained(\n            model_path,\n            torch_dtype=torch.float16,\n            device_map=\"auto\",\n            trust_remote_code=True,\n            local_files_only=use_base\n        )\n        model.eval()\n        print(\"‚úÖ Model loaded\")\n        \n    except Exception as e:\n        print(f\"‚ö†Ô∏è  Fallback to base: {e}\")\n        model = AutoModelForCausalLM.from_pretrained(\n            Config.MODEL_PATH,\n            torch_dtype=torch.float16,\n            device_map=\"auto\",\n            trust_remote_code=True,\n            local_files_only=True\n        )\n        model.eval()\n    \n    test_df = pd.read_csv(\"/kaggle/input/jigsaw-agile-community-rules/test.csv\")\n    \n    all_predictions = []\n    \n    print(f\"\\n{Config.N_TTA} augmentations per sample...\")\n    \n    for idx, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"TTA\"):\n        \n        tta_preds = []\n        \n        # All possible combinations\n        augmentations = [\n            (row['positive_example_1'], row['negative_example_1']),\n            (row['positive_example_2'], row['negative_example_2']),\n            (row['positive_example_1'], row['negative_example_2']),\n            (row['positive_example_2'], row['negative_example_1']),\n            (row['positive_example_1'], row['negative_example_1']),  # Duplicate for stability\n            (row['positive_example_2'], row['negative_example_2']),\n            (row['positive_example_1'] if idx % 2 == 0 else row['positive_example_2'],\n             row['negative_example_1'] if idx % 2 == 0 else row['negative_example_2']),\n        ]\n        \n        for aug_id in range(Config.N_TTA):\n            pos_ex, neg_ex = augmentations[aug_id]\n            \n            messages = [\n                {'role': 'system', 'content': 'You are an expert content moderator. Analyze if the comment violates the rule. Answer only Yes or No.'},\n                {'role': 'user', 'content': f\"\"\"Subreddit: r/{row['subreddit']}\n\nRule: {row['rule']}\n\nExample of VIOLATION:\n{pos_ex}\n\nExample of NON-violation:\n{neg_ex}\n\nComment to analyze:\n{row['body']}\n\nDoes this comment violate the rule?\"\"\"}\n            ]\n            \n            text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n            inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=Config.MAX_LENGTH).to(model.device)\n            \n            with torch.no_grad():\n                logits = model(**inputs).logits[0, -1, :]\n            \n            yes_id = tokenizer.encode(\"Yes\", add_special_tokens=False)[0]\n            no_id = tokenizer.encode(\"No\", add_special_tokens=False)[0]\n            \n            yes_logit = logits[yes_id].cpu().item()\n            no_logit = logits[no_id].cpu().item()\n            \n            prob = np.exp(yes_logit) / (np.exp(yes_logit) + np.exp(no_logit))\n            tta_preds.append(prob)\n        \n        avg_pred = np.mean(tta_preds)\n        all_predictions.append(avg_pred)\n    \n    llm_predictions = np.array(all_predictions)\n    \n    print(f\"\\n‚úÖ TTA complete\")\n    print(f\"   Range: [{llm_predictions.min():.4f}, {llm_predictions.max():.4f}]\")\n    print(f\"   Mean: {llm_predictions.mean():.4f}, Std: {llm_predictions.std():.4f}\")\n    \n    return llm_predictions\n\n\n# =====================================================\n# ENHANCED CLASSICAL ML\n# =====================================================\n\ndef train_enhanced_classical_ml():\n    print(\"\\n\" + \"=\" * 70)\n    print(\"STEP 3: ENHANCED CLASSICAL ML ENSEMBLE\")\n    print(\"=\" * 70)\n    \n    set_seed(Config.SEED)\n    \n    train_df = pd.read_csv(\"/kaggle/input/jigsaw-agile-community-rules/train.csv\")\n    test_df = pd.read_csv(\"/kaggle/input/jigsaw-agile-community-rules/test.csv\")\n    \n    # Multiple feature extractors\n    vectorizer_char = TfidfVectorizer(\n        analyzer='char',\n        ngram_range=(3, 5),\n        max_features=8000,\n        min_df=2,\n        sublinear_tf=True\n    )\n    \n    vectorizer_word = TfidfVectorizer(\n        analyzer='word',\n        ngram_range=(1, 3),\n        max_features=5000,\n        min_df=2,\n        sublinear_tf=True\n    )\n    \n    # Combine features\n    from scipy.sparse import hstack\n    \n    X_train_char = vectorizer_char.fit_transform(train_df['body'])\n    X_train_word = vectorizer_word.fit_transform(train_df['body'])\n    X_train = hstack([X_train_char, X_train_word])\n    \n    X_test_char = vectorizer_char.transform(test_df['body'])\n    X_test_word = vectorizer_word.transform(test_df['body'])\n    X_test = hstack([X_test_char, X_test_word])\n    \n    # Ensemble of classifiers\n    clf1 = LogisticRegression(C=1.5, max_iter=1000, random_state=Config.SEED, class_weight='balanced')\n    clf2 = LogisticRegression(C=0.8, max_iter=1000, random_state=Config.SEED+1)\n    \n    clf1.fit(X_train, train_df['rule_violation'])\n    clf2.fit(X_train, train_df['rule_violation'])\n    \n    pred1 = clf1.predict_proba(X_test)[:, 1]\n    pred2 = clf2.predict_proba(X_test)[:, 1]\n    \n    classical_predictions = (pred1 + pred2) / 2\n    \n    print(f\"‚úÖ Classical ensemble complete\")\n    print(f\"   Range: [{classical_predictions.min():.4f}, {classical_predictions.max():.4f}]\")\n    print(f\"   Mean: {classical_predictions.mean():.4f}\")\n    \n    return classical_predictions\n\n\n# =====================================================\n# VALIDATION\n# =====================================================\n\ndef validate_and_fix_submission(predictions, test_df):\n    sample = pd.read_csv('/kaggle/input/jigsaw-agile-community-rules/sample_submission.csv')\n    \n    submission = pd.DataFrame({\n        'row_id': test_df['row_id'].values,\n        'rule_violation': predictions\n    })\n    \n    submission['row_id'] = submission['row_id'].astype(sample['row_id'].dtype)\n    submission['rule_violation'] = submission['rule_violation'].astype(float).clip(0.0, 1.0)\n    \n    return submission\n\n\n# =====================================================\n# MAIN\n# =====================================================\n\ndef main():\n    import gc\n    \n    set_seed(Config.SEED)\n    \n    torch.cuda.empty_cache()\n    gc.collect()\n    \n    print(\"\\n\" + \"=\" * 70)\n    print(\"JIGSAW - HIGH PERFORMANCE PIPELINE\")\n    print(\"=\" * 70)\n    print(f\"Target: 0.90+ accuracy\")\n    print(f\"Seed: {Config.SEED}\")\n    print(f\"Learning Rate: {Config.LEARNING_RATE}\")\n    print(f\"LoRA R: {Config.LORA_R}\")\n    print(f\"TTA Augmentations: {Config.N_TTA}\")\n    print(f\"Epochs: {Config.N_EPOCHS}\")\n    \n    # Step 1: Fine-tune with enhanced settings\n    model_path, tokenizer, training_successful = finetune_model()\n    \n    # Step 2: Aggressive TTA\n    llm_predictions = inference_with_aggressive_tta(model_path, tokenizer, use_base=not training_successful)\n    \n    # Step 3: Enhanced Classical ML\n    classical_predictions = train_enhanced_classical_ml()\n    \n    # Step 4: Smart Ensemble\n    print(\"\\n\" + \"=\" * 70)\n    print(\"STEP 4: SMART ENSEMBLE\")\n    print(\"=\" * 70)\n    \n    final_predictions = (\n        Config.ENSEMBLE_WEIGHT_LLM * llm_predictions + \n        Config.ENSEMBLE_WEIGHT_CLASSICAL * classical_predictions\n    )\n    \n    print(f\"{Config.ENSEMBLE_WEIGHT_LLM:.1f} LLM + {Config.ENSEMBLE_WEIGHT_CLASSICAL:.1f} Classical\")\n    print(f\"Range: [{final_predictions.min():.4f}, {final_predictions.max():.4f}]\")\n    print(f\"Mean: {final_predictions.mean():.4f}, Std: {final_predictions.std():.4f}\")\n    \n    # Step 5: Save\n    test_df = pd.read_csv(\"/kaggle/input/jigsaw-agile-community-rules/test.csv\")\n    submission = validate_and_fix_submission(final_predictions, test_df)\n    \n    submission.to_csv('submission.csv', index=False)\n    \n    print(\"\\n\" + \"=\" * 70)\n    print(\"FINAL RESULTS\")\n    print(\"=\" * 70)\n    print(submission.head(10).to_string(index=False))\n    \n    print(\"\\n\" + \"=\" * 70)\n    print(\"‚úÖ SUBMISSION READY: submission.csv\")\n    print(\"=\" * 70)\n    \n    if training_successful:\n        print(\"\\nüéØ Expected: 0.88-0.92 (enhanced pipeline)\")\n    else:\n        print(\"\\n‚ö†Ô∏è  Expected: 0.84-0.88 (base model + enhancements)\")\n    \n    bins = [0, 0.2, 0.4, 0.6, 0.8, 1.0]\n    hist, _ = np.histogram(final_predictions, bins=bins)\n    print(\"\\nPrediction distribution:\")\n    for i in range(len(bins)-1):\n        print(f\"  [{bins[i]:.1f}-{bins[i+1]:.1f}]: {hist[i]:3d} ({hist[i]/len(final_predictions)*100:5.1f}%)\")\n    \n    if final_predictions.std() > 0.15:\n        print(\"\\n‚úÖ Excellent variance - diverse predictions!\")\n    else:\n        print(\"\\n‚ö†Ô∏è  Consider: More epochs or bigger LoRA R\")\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T06:57:50.594852Z","iopub.execute_input":"2025-10-15T06:57:50.595157Z","iopub.status.idle":"2025-10-15T07:09:32.618198Z","shell.execute_reply.started":"2025-10-15T06:57:50.595131Z","shell.execute_reply":"2025-10-15T07:09:32.616944Z"}},"outputs":[],"execution_count":null}]}