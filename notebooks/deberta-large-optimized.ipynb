{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimized DeBERTa Ensemble - Expected Best Performance\n",
    "\n",
    "## Overview\n",
    "This notebook implements a carefully optimized version of the DeBERTa ensemble approach, combining the best elements from all previous experiments while avoiding known pitfalls.\n",
    "\n",
    "## Key Optimizations\n",
    "\n",
    "### 1. **Enhanced Training Configuration (Conservative)**\n",
    "- **DeBERTa Main**: 4 epochs (↑ from 3), gradient accumulation=2 for stability\n",
    "- **DeBERTa AUC**: Increased from LR=4e-5 to 3e-5 with 4 epochs for better convergence\n",
    "- **DistilRoBERTa**: 4 epochs (↑ from 3) with improved warmup (0.12)\n",
    "- **Warmup ratio**: 0.12 (↑ from 0.1) for smoother learning rate ramp-up\n",
    "- **No class balancing**: Learned from V2 that this causes overfitting\n",
    "- **Keep MAX_LENGTH=512**: Longer sequences (640) hurt performance in V2\n",
    "\n",
    "### 2. **Improved Prompt Engineering**\n",
    "- Add subreddit context: `r/{subreddit} | Rule: {rule} [SEP] {body}`\n",
    "- Keeps URL semantics extraction (proven effective)\n",
    "- Better contextual understanding without increasing token length excessively\n",
    "\n",
    "### 3. **Optimized Ensemble Weights**\n",
    "- Rebalanced from [0.5, 0.1, 0.1, 0.1, 0.2] to [0.48, 0.12, 0.08, 0.12, 0.20]\n",
    "- More weight to Qwen3 embeddings (0.10→0.12) - semantic search is valuable\n",
    "- More weight to Qwen14B (0.10→0.12) - large model adds diversity\n",
    "- Slightly reduced DeBERTa main (0.50→0.48) to balance ensemble\n",
    "- Reduced DistilRoBERTa (0.10→0.08) as it's the weakest model\n",
    "\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 4. **Gradient Accumulation**\n",
    "- Main DeBERTa: Effective batch size = 8 * 2 = 16\n",
    "- DeBERTa AUC: Effective batch size = 12 * 2 = 24\n",
    "- Better gradient estimates without OOM errors\n",
    "\n",
    "### 5. **Better Regularization**\n",
    "- Weight decay: 0.012 (↑ from 0.01) for slightly stronger regularization\n",
    "- Prevents overfitting while maintaining capacity\n",
    "\n",
    "## Expected Performance\n",
    "- **Target**: 0.92-0.925 AUC\n",
    "- **Current Best**: 0.917 AUC (Experiment 7)\n",
    "- **Expected Gain**: +0.3-0.8 percentage points\n",
    "- **Risk Level**: Low-Medium (conservative optimizations)\n",
    "\n",
    "## Acknowledgments\n",
    "\n",
    "This work builds upon the following Kaggle notebooks:\n",
    "\n",
    "**DeBERTa Large 2epochs 1hr**\n",
    "- Author: [itahiro](https://www.kaggle.com/itahiro)\n",
    "- Notebook: https://www.kaggle.com/code/itahiro/deberta-large-2epochs-1hr\n",
    "- Contribution: Base ensemble architecture, URL semantic extraction\n",
    "\n",
    "**Additional insights from internal experiments:**\n",
    "- Experiment 7 (0.917 AUC): Validated simple approach effectiveness\n",
    "- Experiment 8 V2 (0.914 AUC): Learned that class balancing and long sequences hurt performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile utils.py\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def url_to_semantics(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    url_pattern = r'https?://[^\\s/$.?#].[^\\s]*'\n",
    "    urls = re.findall(url_pattern, text)\n",
    "    \n",
    "    if not urls:\n",
    "        return \"\" \n",
    "\n",
    "    all_semantics = []\n",
    "    seen_semantics = set()\n",
    "\n",
    "    for url in urls:\n",
    "        url_lower = url.lower()\n",
    "        \n",
    "        domain_match = re.search(r\"(?:https?://)?([a-z0-9\\-\\.]+)\\.[a-z]{2,}\", url_lower)\n",
    "        if domain_match:\n",
    "            full_domain = domain_match.group(1)\n",
    "            parts = full_domain.split('.')\n",
    "            for part in parts:\n",
    "                if part and part not in seen_semantics and len(part) > 3:\n",
    "                    all_semantics.append(f\"domain:{part}\")\n",
    "                    seen_semantics.add(part)\n",
    "\n",
    "        path = re.sub(r\"^(?:https?://)?[a-z0-9\\.-]+\\.[a-z]{2,}/?\", \"\", url_lower)\n",
    "        path_parts = [p for p in re.split(r'[/_.-]+', path) if p and p.isalnum()]\n",
    "\n",
    "        for part in path_parts:\n",
    "            part_clean = re.sub(r\"\\.(html?|php|asp|jsp)$|#.*|\\?.*\", \"\", part)\n",
    "            if part_clean and part_clean not in seen_semantics and len(part_clean) > 3:\n",
    "                all_semantics.append(f\"path:{part_clean}\")\n",
    "                seen_semantics.add(part_clean)\n",
    "\n",
    "    if not all_semantics:\n",
    "        return \"\"\n",
    "\n",
    "    return f\"\\nURL Keywords: {' '.join(all_semantics)}\"\n",
    "\n",
    "\n",
    "def get_dataframe_to_train(data_path):\n",
    "    train_dataset = pd.read_csv(f\"{data_path}/train.csv\") \n",
    "    test_dataset = pd.read_csv(f\"{data_path}/test.csv\")\n",
    "\n",
    "    flatten = []\n",
    "\n",
    "    flatten.append(train_dataset[[\"body\", \"rule\", \"subreddit\",\"rule_violation\"]].copy())\n",
    "\n",
    "    for violation_type in [\"positive\", \"negative\"]:\n",
    "        for i in range(1, 3):\n",
    "            col_name = f\"{violation_type}_example_{i}\"\n",
    "            \n",
    "            if col_name in train_dataset.columns:\n",
    "                sub_dataset = train_dataset[[col_name, \"rule\", \"subreddit\"]].copy()\n",
    "                sub_dataset = sub_dataset.rename(columns={col_name: \"body\"})\n",
    "                sub_dataset[\"rule_violation\"] = 1 if violation_type == \"positive\" else 0\n",
    "                \n",
    "                sub_dataset.dropna(subset=['body'], inplace=True)\n",
    "                sub_dataset = sub_dataset[sub_dataset['body'].str.strip().str.len() > 0]\n",
    "                \n",
    "                if not sub_dataset.empty:\n",
    "                    flatten.append(sub_dataset)\n",
    "    \n",
    "    for violation_type in [\"positive\", \"negative\"]:\n",
    "        for i in range(1, 3):\n",
    "            col_name = f\"{violation_type}_example_{i}\"\n",
    "            \n",
    "            if col_name in test_dataset.columns:\n",
    "                sub_dataset = test_dataset[[col_name, \"rule\", \"subreddit\"]].copy()\n",
    "                sub_dataset = sub_dataset.rename(columns={col_name: \"body\"})\n",
    "                sub_dataset[\"rule_violation\"] = 1 if violation_type == \"positive\" else 0\n",
    "                \n",
    "                sub_dataset.dropna(subset=['body'], inplace=True)\n",
    "                sub_dataset = sub_dataset[sub_dataset['body'].str.strip().str.len() > 0]\n",
    "                \n",
    "                if not sub_dataset.empty:\n",
    "                    flatten.append(sub_dataset)\n",
    "    \n",
    "    dataframe = pd.concat(flatten, axis=0)\n",
    "    dataframe = dataframe.drop_duplicates(subset=['body', 'rule', 'subreddit'], ignore_index=True)\n",
    "    dataframe.drop_duplicates(subset=['body','rule'],keep='first',inplace=True)\n",
    "    \n",
    "    return dataframe.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile train_deberta.py\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n",
    "\n",
    "from utils import get_dataframe_to_train, url_to_semantics\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "class CFG:\n",
    "    model_name_or_path = \"/kaggle/input/huggingfacedebertav3variants/deberta-v3-base\"\n",
    "    data_path = \"/kaggle/input/jigsaw-agile-community-rules/\"\n",
    "    output_dir = \"./deberta_v3_small_final_model\"\n",
    "  \n",
    "    EPOCHS = 4  # Increased from 3\n",
    "    LEARNING_RATE = 2e-5  \n",
    "    \n",
    "    MAX_LENGTH = 512\n",
    "    BATCH_SIZE = 8\n",
    "    GRADIENT_ACCUMULATION = 2  # Effective batch size = 16\n",
    "\n",
    "class JigsawDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels:\n",
    "            item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "\n",
    "def main():\n",
    "    seed_everything(42)\n",
    "    training_data_df = get_dataframe_to_train(CFG.data_path)\n",
    "    print(f\"Training dataset size: {len(training_data_df)}\")\n",
    "\n",
    "    test_df_for_prediction = pd.read_csv(f\"{CFG.data_path}/test.csv\")\n",
    "    \n",
    "    # Enhanced prompt with subreddit context\n",
    "    training_data_df['body_with_url'] = training_data_df['body'].apply(lambda x: x + url_to_semantics(x))\n",
    "    training_data_df['input_text'] = \"r/\" + training_data_df['subreddit'] + \" | Rule: \" + training_data_df['rule'] + \"[SEP]\" + training_data_df['body_with_url']\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(CFG.model_name_or_path)\n",
    "    train_encodings = tokenizer(training_data_df['input_text'].tolist(), truncation=True, padding=True, max_length=CFG.MAX_LENGTH)\n",
    "    train_labels = training_data_df['rule_violation'].tolist()\n",
    "    train_dataset = JigsawDataset(train_encodings, train_labels)\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(CFG.model_name_or_path, num_labels=2)\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=CFG.output_dir,\n",
    "        num_train_epochs=CFG.EPOCHS,\n",
    "        learning_rate=CFG.LEARNING_RATE,\n",
    "        per_device_train_batch_size=CFG.BATCH_SIZE,\n",
    "        gradient_accumulation_steps=CFG.GRADIENT_ACCUMULATION,\n",
    "        warmup_ratio=0.12,  # Improved from 0.1\n",
    "        weight_decay=0.012,  # Improved from 0.01\n",
    "        report_to=\"none\",\n",
    "        save_strategy=\"no\",\n",
    "        logging_steps=1,\n",
    "        fp16=True,  # Mixed precision training\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "\n",
    "    test_df_for_prediction['body_with_url'] = test_df_for_prediction['body'].apply(lambda x: x + url_to_semantics(x))\n",
    "    test_df_for_prediction['input_text'] = \"r/\" + test_df_for_prediction['subreddit'] + \" | Rule: \" + test_df_for_prediction['rule'] + \"[SEP]\" + test_df_for_prediction['body_with_url']\n",
    "    \n",
    "    test_encodings = tokenizer(test_df_for_prediction['input_text'].tolist(), truncation=True, padding=True, max_length=CFG.MAX_LENGTH)\n",
    "    test_dataset = JigsawDataset(test_encodings)\n",
    "    \n",
    "    predictions = trainer.predict(test_dataset)\n",
    "    probs = torch.nn.functional.softmax(torch.tensor(predictions.predictions), dim=1)[:, 1].numpy()\n",
    "\n",
    "    submission_df = pd.DataFrame({\n",
    "        \"row_id\": test_df_for_prediction[\"row_id\"],\n",
    "        \"rule_violation\": probs\n",
    "    })\n",
    "    submission_df.to_csv(\"submission_deberta.csv\", index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train_deberta.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile train_distilroberta.py\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n",
    "\n",
    "from utils import get_dataframe_to_train, url_to_semantics\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "class CFG:\n",
    "    model_name_or_path = \"/kaggle/input/distilroberta-base/distilroberta-base\"\n",
    "    data_path = \"/kaggle/input/jigsaw-agile-community-rules/\"\n",
    "    output_dir = \"./distilroberta_final_model\"\n",
    "  \n",
    "    EPOCHS = 4  # Increased from 3\n",
    "    LEARNING_RATE = 2e-5  \n",
    "    \n",
    "    MAX_LENGTH = 512\n",
    "    BATCH_SIZE = 8\n",
    "\n",
    "class JigsawDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels:\n",
    "            item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "\n",
    "def main():\n",
    "    seed_everything(42)\n",
    "    training_data_df = get_dataframe_to_train(CFG.data_path)\n",
    "    print(f\"Training dataset size: {len(training_data_df)}\")\n",
    "\n",
    "    test_df_for_prediction = pd.read_csv(f\"{CFG.data_path}/test.csv\")\n",
    "    \n",
    "    training_data_df['body_with_url'] = training_data_df['body'].apply(lambda x: x + url_to_semantics(x))\n",
    "    training_data_df['input_text'] = \"r/\" + training_data_df['subreddit'] + \" | Rule: \" + training_data_df['rule'] + \"[SEP]\" + training_data_df['body_with_url']\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(CFG.model_name_or_path)\n",
    "    train_encodings = tokenizer(training_data_df['input_text'].tolist(), truncation=True, padding=True, max_length=CFG.MAX_LENGTH)\n",
    "    train_labels = training_data_df['rule_violation'].tolist()\n",
    "    train_dataset = JigsawDataset(train_encodings, train_labels)\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(CFG.model_name_or_path, num_labels=2)\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=CFG.output_dir,\n",
    "        num_train_epochs=CFG.EPOCHS,\n",
    "        learning_rate=CFG.LEARNING_RATE,\n",
    "        per_device_train_batch_size=CFG.BATCH_SIZE,\n",
    "        warmup_ratio=0.12,\n",
    "        weight_decay=0.012,\n",
    "        report_to=\"none\",\n",
    "        save_strategy=\"no\",\n",
    "        logging_steps=1,\n",
    "        fp16=True,\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "\n",
    "    test_df_for_prediction['body_with_url'] = test_df_for_prediction['body'].apply(lambda x: x + url_to_semantics(x))\n",
    "    test_df_for_prediction['input_text'] = \"r/\" + test_df_for_prediction['subreddit'] + \" | Rule: \" + test_df_for_prediction['rule'] + \"[SEP]\" + test_df_for_prediction['body_with_url']\n",
    "    \n",
    "    test_encodings = tokenizer(test_df_for_prediction['input_text'].tolist(), truncation=True, padding=True, max_length=CFG.MAX_LENGTH)\n",
    "    test_dataset = JigsawDataset(test_encodings)\n",
    "    \n",
    "    predictions = trainer.predict(test_dataset)\n",
    "    probs = torch.nn.functional.softmax(torch.tensor(predictions.predictions), dim=1)[:, 1].numpy()\n",
    "\n",
    "    submission_df = pd.DataFrame({\n",
    "        \"row_id\": test_df_for_prediction[\"row_id\"],\n",
    "        \"rule_violation\": probs\n",
    "    })\n",
    "    submission_df.to_csv(\"submission_distilroberta.csv\", index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train_distilroberta.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile train_deberta_auc.py\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n",
    "\n",
    "from utils import get_dataframe_to_train, url_to_semantics\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "class CFG:\n",
    "    model_name_or_path = \"/kaggle/input/huggingfacedebertav3variants/deberta-v3-base\"\n",
    "    data_path = \"/kaggle/input/jigsaw-agile-community-rules/\"\n",
    "    output_dir = \"./deberta_auc_final_model\"\n",
    "  \n",
    "    EPOCHS = 4  # Increased from 3\n",
    "    LEARNING_RATE = 3e-5  # Adjusted from 4e-5 for better convergence\n",
    "    \n",
    "    MAX_LENGTH = 512\n",
    "    BATCH_SIZE = 12\n",
    "    GRADIENT_ACCUMULATION = 2  # Effective batch size = 24\n",
    "\n",
    "class JigsawDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels:\n",
    "            item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "\n",
    "def main():\n",
    "    seed_everything(42)\n",
    "    training_data_df = get_dataframe_to_train(CFG.data_path)\n",
    "    print(f\"Training dataset size: {len(training_data_df)}\")\n",
    "\n",
    "    test_df_for_prediction = pd.read_csv(f\"{CFG.data_path}/test.csv\")\n",
    "    \n",
    "    training_data_df['body_with_url'] = training_data_df['body'].apply(lambda x: x + url_to_semantics(x))\n",
    "    training_data_df['input_text'] = \"r/\" + training_data_df['subreddit'] + \" | Rule: \" + training_data_df['rule'] + \"[SEP]\" + training_data_df['body_with_url']\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(CFG.model_name_or_path)\n",
    "    train_encodings = tokenizer(training_data_df['input_text'].tolist(), truncation=True, padding=True, max_length=CFG.MAX_LENGTH)\n",
    "    train_labels = training_data_df['rule_violation'].tolist()\n",
    "    train_dataset = JigsawDataset(train_encodings, train_labels)\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(CFG.model_name_or_path, num_labels=2)\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=CFG.output_dir,\n",
    "        num_train_epochs=CFG.EPOCHS,\n",
    "        learning_rate=CFG.LEARNING_RATE,\n",
    "        per_device_train_batch_size=CFG.BATCH_SIZE,\n",
    "        gradient_accumulation_steps=CFG.GRADIENT_ACCUMULATION,\n",
    "        warmup_ratio=0.12,\n",
    "        weight_decay=0.012,\n",
    "        report_to=\"none\",\n",
    "        save_strategy=\"no\",\n",
    "        logging_steps=1,\n",
    "        fp16=True,\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "\n",
    "    test_df_for_prediction['body_with_url'] = test_df_for_prediction['body'].apply(lambda x: x + url_to_semantics(x))\n",
    "    test_df_for_prediction['input_text'] = \"r/\" + test_df_for_prediction['subreddit'] + \" | Rule: \" + test_df_for_prediction['rule'] + \"[SEP]\" + test_df_for_prediction['body_with_url']\n",
    "    \n",
    "    test_encodings = tokenizer(test_df_for_prediction['input_text'].tolist(), truncation=True, padding=True, max_length=CFG.MAX_LENGTH)\n",
    "    test_dataset = JigsawDataset(test_encodings)\n",
    "    \n",
    "    predictions = trainer.predict(test_dataset)\n",
    "    probs = torch.nn.functional.softmax(torch.tensor(predictions.predictions), dim=1)[:, 1].numpy()\n",
    "\n",
    "    submission_df = pd.DataFrame({\n",
    "        \"row_id\": test_df_for_prediction[\"row_id\"],\n",
    "        \"rule_violation\": probs\n",
    "    })\n",
    "    submission_df.to_csv(\"submission_debertaauc.csv\", index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train_deberta_auc.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile constants.py\n",
    "EMBDEDDING_MODEL_PATH = \"/kaggle/input/qwen-3-embedding/transformers/0.6b/1\"\n",
    "MODEL_OUTPUT_PATH = '/kaggle/input/qwen3-8b-embedding'\n",
    "DATA_PATH = \"/kaggle/input/jigsaw-agile-community-rules\"\n",
    "\n",
    "# https://huggingface.co/Qwen/Qwen3-Embedding-0.6B/blob/main/config_sentence_transformers.json\n",
    "EMBEDDING_MODEL_QUERY = \"Instruct: Given a web search query, retrieve relevant passages that answer the query\\nQuery:\"\n",
    "\n",
    "CLEAN_TEXT = True\n",
    "TOP_K = 2000\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile utils_semantic.py\n",
    "import pandas as pd\n",
    "import torch.distributed as dist\n",
    "\n",
    "from datasets import Dataset\n",
    "from cleantext import clean\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from constants import CLEAN_TEXT\n",
    "\n",
    "\n",
    "def build_prompt(row):\n",
    "    return f\"\"\"r/{row[\"subreddit\"]}\\nComment: {row[\"body\"]}\"\"\"\n",
    "\n",
    "\n",
    "def cleaner(text):\n",
    "    return clean(\n",
    "        text,\n",
    "        fix_unicode=True,\n",
    "        to_ascii=True,\n",
    "        lower=False,\n",
    "        no_line_breaks=False,\n",
    "        no_urls=True,\n",
    "        no_emails=True,\n",
    "        no_phone_numbers=True,\n",
    "        no_numbers=False,\n",
    "        no_digits=False,\n",
    "        no_currency_symbols=False,\n",
    "        no_punct=False,\n",
    "        replace_with_url=\"<URL>\",\n",
    "        replace_with_email=\"<EMAIL>\",\n",
    "        replace_with_phone_number=\"<PHONE>\",\n",
    "        lang=\"en\",\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def get_dataframe_to_train(data_path):\n",
    "    train_dataset = pd.read_csv(f\"{data_path}/train.csv\")\n",
    "    test_dataset = pd.read_csv(f\"{data_path}/test.csv\").sample(frac=0.6, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    flatten = []\n",
    "    flatten.append(train_dataset[[\"body\", \"rule\", \"subreddit\", \"rule_violation\"]])\n",
    "    \n",
    "    for violation_type in [\"positive\", \"negative\"]:\n",
    "        for i in range(1, 3):\n",
    "            sub_dataset = test_dataset[[f\"{violation_type}_example_{i}\", \"rule\", \"subreddit\"]].copy()\n",
    "            sub_dataset = sub_dataset.rename(columns={f\"{violation_type}_example_{i}\": \"body\"})\n",
    "            sub_dataset[\"rule_violation\"] = 1 if violation_type == \"positive\" else 0\n",
    "            flatten.append(sub_dataset)\n",
    "\n",
    "    dataframe = pd.concat(flatten, axis=0)    \n",
    "    dataframe = dataframe.drop_duplicates(ignore_index=True)\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def prepare_dataframe(dataframe):\n",
    "    dataframe[\"prompt\"] = dataframe.apply(build_prompt, axis=1)\n",
    "\n",
    "    \n",
    "    if CLEAN_TEXT:\n",
    "        tqdm.pandas(desc=\"cleaner\")\n",
    "        dataframe[\"prompt\"] = dataframe[\"prompt\"].progress_apply(cleaner)\n",
    "\n",
    "    if \"rule_violation\" in dataframe.columns:\n",
    "        dataframe[\"rule_violation\"] = dataframe[\"rule_violation\"].map(\n",
    "            {\n",
    "                1: 1,\n",
    "                0: -1,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile semantic.py\n",
    "import pandas as pd\n",
    "from transformers import AutoModel, AutoModelForCausalLM, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.util import semantic_search, dot_score\n",
    "from tqdm.auto import tqdm\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "\n",
    "from utils_semantic import get_dataframe_to_train, prepare_dataframe\n",
    "from constants import DATA_PATH, EMBDEDDING_MODEL_PATH, EMBEDDING_MODEL_QUERY, TOP_K, BATCH_SIZE, MODEL_OUTPUT_PATH\n",
    "\n",
    "\n",
    "\n",
    "def get_scores(test_dataframe):\n",
    "    corpus_dataframe = get_dataframe_to_train(DATA_PATH)\n",
    "    corpus_dataframe = prepare_dataframe(corpus_dataframe)\n",
    "    \n",
    "    # Load base model\n",
    "    model = AutoModelForCausalLM.from_pretrained(EMBDEDDING_MODEL_PATH)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(EMBDEDDING_MODEL_PATH)\n",
    "    \n",
    "    # Load adapter configuration and model\n",
    "    adapter_config = PeftConfig.from_pretrained(MODEL_OUTPUT_PATH)\n",
    "    lora_model = PeftModel.from_pretrained(model, MODEL_OUTPUT_PATH, config=adapter_config)\n",
    "    merged_model = lora_model.merge_and_unload()\n",
    "    tokenizer.save_pretrained(\"Qwen3Emb_Finetuned\")\n",
    "    merged_model.save_pretrained(\"Qwen3Emb_Finetuned\")\n",
    "\n",
    "    embedding_model = SentenceTransformer(model_name_or_path=\"Qwen3Emb_Finetuned\", device=\"cuda\")\n",
    "\n",
    "    print('Done loading model!')\n",
    "\n",
    "    result = []\n",
    "    for rule in tqdm(test_dataframe[\"rule\"].unique(), desc=f\"Generate scores for each rule\"):\n",
    "        test_dataframe_part = test_dataframe.query(\"rule == @rule\").reset_index(drop=True)\n",
    "        corpus_dataframe_part = corpus_dataframe.query(\"rule == @rule\").reset_index(drop=True)\n",
    "        corpus_dataframe_part = corpus_dataframe_part.reset_index(names=\"row_id\")\n",
    "        \n",
    "        query_embeddings = embedding_model.encode(\n",
    "            sentences=test_dataframe_part[\"prompt\"].tolist(),\n",
    "            prompt=EMBEDDING_MODEL_QUERY,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            show_progress_bar=True,\n",
    "            convert_to_tensor=True,\n",
    "            device=\"cuda\",\n",
    "            normalize_embeddings=True,\n",
    "        )\n",
    "        document_embeddings = embedding_model.encode(\n",
    "            sentences=corpus_dataframe_part[\"prompt\"].tolist(),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            show_progress_bar=True,\n",
    "            convert_to_tensor=True,\n",
    "            device=\"cuda\",\n",
    "            normalize_embeddings=True,\n",
    "        )\n",
    "        test_dataframe_part[\"semantic\"] = semantic_search(\n",
    "            query_embeddings,\n",
    "            document_embeddings,\n",
    "            top_k=TOP_K,\n",
    "            score_function=dot_score,\n",
    "        )\n",
    "        def get_score(semantic):\n",
    "            semantic = pd.DataFrame(semantic)\n",
    "            semantic = semantic.merge(\n",
    "                corpus_dataframe_part[[\"row_id\", \"rule_violation\"]],\n",
    "                how=\"left\",\n",
    "                left_on=\"corpus_id\",\n",
    "                right_on=\"row_id\",\n",
    "            )\n",
    "            semantic[\"score\"] = semantic[\"score\"]*semantic[\"rule_violation\"]\n",
    "            return semantic[\"score\"].sum()\n",
    "            \n",
    "        tqdm.pandas(desc=f\"Add label for {rule=}\")\n",
    "        test_dataframe_part[\"rule_violation\"] = test_dataframe_part[\"semantic\"].progress_apply(get_score)\n",
    "        result.append(test_dataframe_part[[\"row_id\", \"rule_violation\"]].copy())\n",
    "        \n",
    "    submission = pd.concat(result, axis=0)\n",
    "    return submission\n",
    "\n",
    "\n",
    "def generate_submission():\n",
    "    test_dataframe = pd.read_csv(f\"{DATA_PATH}/test.csv\")\n",
    "    test_dataframe = prepare_dataframe(test_dataframe)\n",
    "    \n",
    "    submission = get_scores(test_dataframe)\n",
    "    submission = test_dataframe[[\"row_id\"]].merge(submission, on=\"row_id\", how=\"left\")\n",
    "    submission.to_csv(\"submission_qwen3.csv\", index=False)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_submission()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python semantic.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile infer_qwen.py\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from logits_processor_zoo.vllm import MultipleChoiceLogitsProcessor\n",
    "import torch\n",
    "import vllm\n",
    "import numpy as np\n",
    "from vllm.lora.request import LoRARequest\n",
    "import argparse\n",
    "from scipy.special import softmax\n",
    "df = pd.read_csv(\"/kaggle/input/jigsaw-agile-community-rules/test.csv\")\n",
    "\n",
    "MODEL_NAME = \"/kaggle/input/qwen2.5/transformers/14b-instruct-gptq-int4/1\"\n",
    "LORA_PATH = \"/kaggle/input/lora_14b_gptq_1epoch_r32/keras/default/1\"\n",
    "if __name__=='__main__':\n",
    "    os.environ[\"VLLM_USE_V1\"] = \"0\"\n",
    "\n",
    "    llm = vllm.LLM(\n",
    "        MODEL_NAME,\n",
    "        quantization='gptq',\n",
    "        tensor_parallel_size=torch.cuda.device_count(),\n",
    "        gpu_memory_utilization=0.98,\n",
    "        trust_remote_code=True,\n",
    "        dtype=\"half\",\n",
    "        enforce_eager=True,\n",
    "        max_model_len=2836,\n",
    "        disable_log_stats=True,\n",
    "        enable_prefix_caching=True,\n",
    "        enable_lora=True,\n",
    "        max_lora_rank=32\n",
    "    )\n",
    "    tokenizer = llm.get_tokenizer()\n",
    "    SYS_PROMPT = \"\"\"\n",
    "You are given a comment on reddit. Your task is to classify if it violates the given rule. Only respond Yes/No.\n",
    "\"\"\"\n",
    "    \n",
    "    prompts = []\n",
    "    for i, row in df.iterrows():\n",
    "        text = f\"\"\"\n",
    "    r/{row.subreddit}\n",
    "    Rule: {row.rule}\n",
    "    \n",
    "    1) {row.positive_example_1}\n",
    "    Violation: Yes\n",
    "    \n",
    "    2) {row.positive_example_2}\n",
    "    Violation: Yes\n",
    "    \n",
    "    3) {row.negative_example_1}\n",
    "    Violation: No\n",
    "    \n",
    "    4) {row.negative_example_2}\n",
    "    Violation: No\n",
    "    \n",
    "    5) {row.body}\n",
    "    \"\"\"\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": SYS_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": text}\n",
    "        ]\n",
    "    \n",
    "        prompt = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            add_generation_prompt=True,\n",
    "            tokenize=False,\n",
    "        ) + \"Answer:\"\n",
    "        prompts.append(prompt)\n",
    "    \n",
    "    df[\"prompt\"] = prompts\n",
    "    \n",
    "    mclp = MultipleChoiceLogitsProcessor(tokenizer, choices=['Yes','No'])\n",
    "    outputs = llm.generate(\n",
    "        prompts,\n",
    "        vllm.SamplingParams(\n",
    "            skip_special_tokens=True,\n",
    "            max_tokens=1,\n",
    "            logits_processors=[mclp],\n",
    "            logprobs=2,\n",
    "        ),\n",
    "        use_tqdm=True,\n",
    "        lora_request=LoRARequest(\"default\", 1, LORA_PATH)\n",
    "    )\n",
    "    logprobs = [\n",
    "        {lp.decoded_token: lp.logprob for lp in out.outputs[0].logprobs[0].values()}\n",
    "        for out in outputs\n",
    "    ]\n",
    "    logit_matrix = pd.DataFrame(logprobs)[['Yes','No']]\n",
    "    df = pd.concat([df, logit_matrix], axis=1)\n",
    "    \n",
    "    df[['Yes',\"No\"]] = df[['Yes',\"No\"]].apply(lambda x: softmax(x.values), axis=1, result_type=\"expand\")\n",
    "    df[\"pred\"] = df[\"Yes\"]\n",
    "    df['rule_violation'] = df[\"pred\"]\n",
    "    df[['row_id', 'rule_violation']].to_csv(\"submission_qwen14b.csv\",index=False)\n",
    "    pd.read_csv('submission_qwen14b.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python infer_qwen.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load all model predictions\n",
    "q = pd.read_csv('submission_deberta.csv')\n",
    "l = pd.read_csv('submission_qwen3.csv')\n",
    "m = pd.read_csv('submission_distilroberta.csv')\n",
    "w = pd.read_csv('submission_qwen14b.csv')\n",
    "a = pd.read_csv('submission_debertaauc.csv')\n",
    "\n",
    "# Rank normalization\n",
    "rq = q['rule_violation'].rank(method='average') / (len(q)+1)\n",
    "rl = l['rule_violation'].rank(method='average') / (len(l)+1)\n",
    "rm = m['rule_violation'].rank(method='average') / (len(m)+1)\n",
    "rw = w['rule_violation'].rank(method='average') / (len(w)+1)\n",
    "ra = a['rule_violation'].rank(method='average') / (len(a)+1)\n",
    "\n",
    "# Optimized ensemble weights: [0.48, 0.12, 0.08, 0.12, 0.20]\n",
    "# DeBERTa: 0.48 (slightly reduced from 0.5)\n",
    "# Qwen3: 0.12 (increased from 0.1 - semantic search is valuable)\n",
    "# DistilRoBERTa: 0.08 (reduced from 0.1 - weakest model)\n",
    "# Qwen14B: 0.12 (increased from 0.1 - large model diversity)\n",
    "# DeBERTa AUC: 0.20 (unchanged - strong performer)\n",
    "blend = 0.48*rq + 0.12*rl + 0.08*rm + 0.12*rw + 0.20*ra\n",
    "\n",
    "q['rule_violation'] = blend\n",
    "q.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "\n",
    "print(\"Ensemble complete!\")\n",
    "print(f\"Prediction statistics:\")\n",
    "print(f\"  Mean: {blend.mean():.4f}\")\n",
    "print(f\"  Std:  {blend.std():.4f}\")\n",
    "print(f\"  Min:  {blend.min():.4f}\")\n",
    "print(f\"  Max:  {blend.max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('/kaggle/working/submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Improvements\n",
    "\n",
    "This notebook implements **conservative, proven optimizations** over the baseline 0.917 AUC:\n",
    "\n",
    "1. **Training**: +1 epoch for key models (3→4), better warmup (0.1→0.12), gradient accumulation\n",
    "2. **Prompts**: Added subreddit context without increasing MAX_LENGTH\n",
    "3. **Ensemble**: Rebalanced weights to give more credit to semantic search and large model\n",
    "4. **Regularization**: Slightly increased weight decay (0.01→0.012)\n",
    "5. **Stability**: FP16 training, gradient accumulation for better estimates\n",
    "\n",
    "**What we avoided (learned from V2 failure):**\n",
    "- ❌ Class balancing (caused overfitting)\n",
    "- ❌ Excessive training (5 epochs too many)\n",
    "- ❌ Long sequences (640 tokens hurt performance)\n",
    "- ❌ Validation splits during training (reduces training data)\n",
    "\n",
    "**Expected outcome:** 0.92-0.925 AUC (conservative +0.3-0.8% gain)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
