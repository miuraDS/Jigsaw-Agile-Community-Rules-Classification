{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":94635,"databundleVersionId":13121456,"sourceType":"competition"},{"sourceId":4620664,"sourceType":"datasetVersion","datasetId":2663421},{"sourceId":6851361,"sourceType":"datasetVersion","datasetId":3938197},{"sourceId":12762469,"sourceType":"datasetVersion","datasetId":8067935},{"sourceId":166236,"sourceType":"modelInstanceVersion","modelInstanceId":141449,"modelId":164048},{"sourceId":171496,"sourceType":"modelInstanceVersion","modelInstanceId":145960,"modelId":164048},{"sourceId":182534,"sourceType":"modelInstanceVersion","modelInstanceId":155593,"modelId":178059},{"sourceId":426330,"sourceType":"modelInstanceVersion","modelInstanceId":347541,"modelId":368803},{"sourceId":521642,"sourceType":"modelInstanceVersion","modelInstanceId":410134,"modelId":222398},{"sourceId":523492,"sourceType":"modelInstanceVersion","modelInstanceId":411182,"modelId":429004}],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Acknowledgments\n\nThis work builds upon the following Kaggle notebook:\n\n**DeBERTa Large 2epochs 1hr**\n- Author: [itahiro](https://www.kaggle.com/itahiro)\n- Notebook: https://www.kaggle.com/code/itahiro/deberta-large-2epochs-1hr","metadata":{}},{"cell_type":"code","source":"# !uv pip install -q googletrans-py==4.0.0   # ← maintained fork, no version clashes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T03:04:43.944225Z","iopub.execute_input":"2025-09-23T03:04:43.944483Z","iopub.status.idle":"2025-09-23T03:04:43.948467Z","shell.execute_reply.started":"2025-09-23T03:04:43.944459Z","shell.execute_reply":"2025-09-23T03:04:43.947785Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# %%writefile rule_augmenter.py\n# \"\"\"\n# Create 3 synthetic variants of every rule by round-trip translation.\n# Cached in /kaggle/working/synthetic_rules.json so the mapping is\n# fixed for both train and (later) inference.\n# \"\"\"\n# import json, random, os\n# from googletrans import Translator  # lightweight, works offline-cached\n# random.seed(42)\n\n# TRANS_LANGS = ['fr', 'de', 'es']      # 3 langs → 3 synthetic rules\n# CACHE_FILE  = '/kaggle/working/synthetic_rules.json'\n# translator  = Translator()\n\n# def _round_trip(text, lang):\n#     \"\"\"en → lang → en\"\"\"\n#     return translator.translate(translator.translate(text, dest=lang).text, dest='en').text\n\n# def build_synthetic_rule_map(unique_rules):\n#     \"\"\"Dict original_rule → list of 3 synthetic rules\"\"\"\n#     if os.path.exists(CACHE_FILE):\n#         return json.load(open(CACHE_FILE))\n#     synth = {}\n#     for rule in unique_rules:\n#         synth[rule] = [_round_trip(rule, lg) for lg in TRANS_LANGS]\n#     json.dump(synth, open(CACHE_FILE, 'w'), indent=2)\n#     return synth","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T03:04:43.949059Z","iopub.execute_input":"2025-09-23T03:04:43.949307Z","iopub.status.idle":"2025-09-23T03:04:43.964038Z","shell.execute_reply.started":"2025-09-23T03:04:43.949281Z","shell.execute_reply":"2025-09-23T03:04:43.963315Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile utils.py\nimport pandas as pd\nimport re\n\n# from rule_augmenter import build_synthetic_rule_map\n\ndef url_to_semantics(text: str) -> str:\n    if not isinstance(text, str):\n        return \"\"\n\n    url_pattern = r'https?://[^\\s/$.?#].[^\\s]*'\n    urls = re.findall(url_pattern, text)\n    \n    if not urls:\n        return \"\" \n\n    all_semantics = []\n    seen_semantics = set()\n\n    for url in urls:\n        url_lower = url.lower()\n        \n        domain_match = re.search(r\"(?:https?://)?([a-z0-9\\-\\.]+)\\.[a-z]{2,}\", url_lower)\n        if domain_match:\n            full_domain = domain_match.group(1)\n            parts = full_domain.split('.')\n            for part in parts:\n                if part and part not in seen_semantics and len(part) > 3: # Avoid short parts like 'www'\n                    all_semantics.append(f\"domain:{part}\")\n                    seen_semantics.add(part)\n\n        # 2. Extract path parts\n        path = re.sub(r\"^(?:https?://)?[a-z0-9\\.-]+\\.[a-z]{2,}/?\", \"\", url_lower)\n        path_parts = [p for p in re.split(r'[/_.-]+', path) if p and p.isalnum()] # Split by common delimiters\n\n        for part in path_parts:\n            # Clean up potential file extensions or query params\n            part_clean = re.sub(r\"\\.(html?|php|asp|jsp)$|#.*|\\?.*\", \"\", part)\n            if part_clean and part_clean not in seen_semantics and len(part_clean) > 3:\n                all_semantics.append(f\"path:{part_clean}\")\n                seen_semantics.add(part_clean)\n\n    if not all_semantics:\n        return \"\"\n\n    return f\"\\nURL Keywords: {' '.join(all_semantics)}\"\n\n\ndef get_dataframe_to_train(data_path):\n    train_dataset = pd.read_csv(f\"{data_path}/train.csv\") \n    test_dataset = pd.read_csv(f\"{data_path}/test.csv\")\n\n    flatten = []\n\n    flatten.append(train_dataset[[\"body\", \"rule\", \"subreddit\",\"rule_violation\"]].copy())\n\n    for violation_type in [\"positive\", \"negative\"]:\n        for i in range(1, 3):\n            col_name = f\"{violation_type}_example_{i}\"\n            \n            if col_name in train_dataset.columns:\n                sub_dataset = train_dataset[[col_name, \"rule\", \"subreddit\"]].copy()\n                sub_dataset = sub_dataset.rename(columns={col_name: \"body\"})\n                sub_dataset[\"rule_violation\"] = 1 if violation_type == \"positive\" else 0\n                \n                sub_dataset.dropna(subset=['body'], inplace=True)\n                sub_dataset = sub_dataset[sub_dataset['body'].str.strip().str.len() > 0]\n                \n                if not sub_dataset.empty:\n                    flatten.append(sub_dataset)\n    \n    for violation_type in [\"positive\", \"negative\"]:\n        for i in range(1, 3):\n            col_name = f\"{violation_type}_example_{i}\"\n            \n            if col_name in test_dataset.columns:\n                sub_dataset = test_dataset[[col_name, \"rule\", \"subreddit\"]].copy()\n                sub_dataset = sub_dataset.rename(columns={col_name: \"body\"})\n                sub_dataset[\"rule_violation\"] = 1 if violation_type == \"positive\" else 0\n                \n                sub_dataset.dropna(subset=['body'], inplace=True)\n                sub_dataset = sub_dataset[sub_dataset['body'].str.strip().str.len() > 0]\n                \n                if not sub_dataset.empty:\n                    flatten.append(sub_dataset)\n    \n    dataframe = pd.concat(flatten, axis=0)\n    dataframe = dataframe.drop_duplicates(subset=['body', 'rule', 'subreddit'], ignore_index=True)\n    dataframe.drop_duplicates(subset=['body','rule'],keep='first',inplace=True)\n    \n    return dataframe.sample(frac=1, random_state=42).reset_index(drop=True)\n    \n# def get_dataframe_to_train(data_path):\n#     \"\"\"\n#     Load TRAIN only for real comments (labels exist),\n#     append ALL examples from train + test,\n#     create 3 synthetic rules per original rule,\n#     return augmented, de-duplicated, shuffled DataFrame.\n#     \"\"\"\n#     train_df = pd.read_csv(f\"{data_path}/train.csv\")\n#     test_df  = pd.read_csv(f\"{data_path}/test.csv\")\n\n#     # 1. synthetic rule map from **union** of rules (train + test)\n#     unique_rules = pd.concat([train_df, test_df])['rule'].unique()\n#     rule_map     = build_synthetic_rule_map(unique_rules)\n\n#     # 2. real comments → ONLY from train (have labels)\n#     base = train_df[[\"body\", \"rule\", \"subreddit\", \"rule_violation\"]].copy()\n\n#     # 3. helper: augment a dataframe (original + 3 synthetic rules per row)\n#     def _augment(df):\n#         rows = []\n#         for _, r in df.iterrows():\n#             rows.append(r.copy())                # keep original\n#             for syn_rule in rule_map[r['rule']]: # 3 synthetic variants\n#                 rr = r.copy()\n#                 rr['rule'] = syn_rule\n#                 rows.append(rr)\n#         return pd.DataFrame(rows)\n\n#     # 4. collect **all example rows** (pos/neg × 1,2) from **both** files\n#     flatten = [base]\n#     for df in (train_df, test_df):\n#         for vt in [\"positive\", \"negative\"]:\n#             for i in (1, 2):\n#                 col = f\"{vt}_example_{i}\"\n#                 if col not in df.columns:\n#                     continue\n#                 tmp = df[[col, \"rule\", \"subreddit\"]].rename(columns={col: \"body\"})\n#                 tmp[\"rule_violation\"] = 1 if vt == \"positive\" else 0\n#                 tmp = tmp.dropna(subset=[\"body\"])\n#                 tmp = tmp[tmp[\"body\"].str.strip().str.len() > 0]\n#                 if not tmp.empty:\n#                     flatten.append(tmp)\n\n#     # 5. augment the whole pool\n#     pool = pd.concat(flatten, ignore_index=True)\n#     pool = _augment(pool)          # synthetic rules added here\n\n#     # 6. de-duplicate & shuffle\n#     pool = pool.drop_duplicates(subset=[\"body\", \"rule\", \"subreddit\"], ignore_index=True)\n#     pool = pool.drop_duplicates(subset=[\"body\"], keep=\"first\")\n#     return pool.sample(frac=1, random_state=42).reset_index(drop=True)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-23T03:04:43.965469Z","iopub.execute_input":"2025-09-23T03:04:43.965704Z","iopub.status.idle":"2025-09-23T03:04:43.982339Z","shell.execute_reply.started":"2025-09-23T03:04:43.965684Z","shell.execute_reply":"2025-09-23T03:04:43.981632Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile train_deberta.py\nimport os\nimport pandas as pd\nimport torch\nimport random\nimport numpy as np\nfrom sklearn.model_selection import train_test_split \nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    Trainer,\n    TrainingArguments\n)\n\nfrom utils import get_dataframe_to_train, url_to_semantics\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed) \n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nclass CFG:\n    model_name_or_path = \"/kaggle/input/huggingfacedebertav3variants/deberta-v3-base\"\n    data_path = \"/kaggle/input/jigsaw-agile-community-rules/\"\n    output_dir = \"./deberta_v3_small_final_model\"\n  \n    EPOCHS = 3\n    LEARNING_RATE = 2e-5  \n    \n    MAX_LENGTH = 512\n    BATCH_SIZE = 8\n\nclass JigsawDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels=None):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        if self.labels:\n            item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.encodings['input_ids'])\n\ndef main():\n    seed_everything(42)\n    training_data_df = get_dataframe_to_train(CFG.data_path)\n    # training_data_df, valid_df = train_test_split(full_df,test_size=0.2,stratify=full_df['rule'],random_state=42)\n    print(f\"Training dataset (from examples only) size: {len(training_data_df)}\")\n\n    test_df_for_prediction = pd.read_csv(f\"{CFG.data_path}/test.csv\")\n    \n    training_data_df['body_with_url'] = training_data_df['body'].apply(lambda x: x + url_to_semantics(x))\n    training_data_df['input_text'] = training_data_df['rule'] + \"[SEP]\" + training_data_df['body_with_url']\n\n    tokenizer = AutoTokenizer.from_pretrained(CFG.model_name_or_path)\n    train_encodings = tokenizer(training_data_df['input_text'].tolist(), truncation=True, padding=True, max_length=CFG.MAX_LENGTH)\n    train_labels = training_data_df['rule_violation'].tolist()\n    train_dataset = JigsawDataset(train_encodings, train_labels)\n\n    model = AutoModelForSequenceClassification.from_pretrained(CFG.model_name_or_path, num_labels=2)\n    \n    training_args = TrainingArguments(\n        output_dir=CFG.output_dir,\n        num_train_epochs=CFG.EPOCHS,\n        learning_rate=CFG.LEARNING_RATE,\n        per_device_train_batch_size=CFG.BATCH_SIZE,\n        warmup_ratio=0.1,\n        weight_decay=0.01,\n        report_to=\"none\",\n        save_strategy=\"no\",  #这一行加上这个 save_strategy=\"no\"\n        logging_steps=1,\n    )\n    \n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n    )\n    \n    trainer.train()\n\n    test_df_for_prediction['body_with_url'] = test_df_for_prediction['body'].apply(lambda x: x + url_to_semantics(x))\n    test_df_for_prediction['input_text'] = test_df_for_prediction['rule'] + \"[SEP]\" + test_df_for_prediction['body_with_url']\n    \n    test_encodings = tokenizer(test_df_for_prediction['input_text'].tolist(), truncation=True, padding=True, max_length=CFG.MAX_LENGTH)\n    test_dataset = JigsawDataset(test_encodings)\n    \n    predictions = trainer.predict(test_dataset)\n    probs = torch.nn.functional.softmax(torch.tensor(predictions.predictions), dim=1)[:, 1].numpy()\n\n    submission_df = pd.DataFrame({\n        \"row_id\": test_df_for_prediction[\"row_id\"],\n        \"rule_violation\": probs\n    })\n    submission_df.to_csv(\"submission_deberta.csv\", index=False)\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T03:04:44.093296Z","iopub.execute_input":"2025-09-23T03:04:44.093852Z","iopub.status.idle":"2025-09-23T03:04:44.100601Z","shell.execute_reply.started":"2025-09-23T03:04:44.093821Z","shell.execute_reply":"2025-09-23T03:04:44.099829Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python train_deberta.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T03:43:03.110246Z","iopub.execute_input":"2025-09-23T03:43:03.110874Z","iopub.status.idle":"2025-09-23T03:43:03.122869Z","shell.execute_reply.started":"2025-09-23T03:43:03.110842Z","shell.execute_reply":"2025-09-23T03:43:03.12215Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile train_distilroberta.py\nimport os\nimport pandas as pd\nimport torch\nimport random\nimport numpy as np\nfrom sklearn.model_selection import train_test_split \nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    Trainer,\n    TrainingArguments\n)\n\nfrom utils import get_dataframe_to_train, url_to_semantics\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed) \n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nclass CFG:\n    model_name_or_path = \"/kaggle/input/distilroberta-base/distilroberta-base\"\n    data_path = \"/kaggle/input/jigsaw-agile-community-rules/\"\n    output_dir = \"./deberta_v3_small_final_model\"\n  \n    EPOCHS = 3\n    LEARNING_RATE = 2e-5  \n    \n    MAX_LENGTH = 512\n    BATCH_SIZE = 8\n\nclass JigsawDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels=None):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        if self.labels:\n            item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.encodings['input_ids'])\n\ndef main():\n    seed_everything(42)\n    training_data_df = get_dataframe_to_train(CFG.data_path)\n    # training_data_df, valid_df = train_test_split(full_df,test_size=0.2,stratify=full_df['rule'],random_state=42)\n    print(f\"Training dataset (from examples only) size: {len(training_data_df)}\")\n\n    test_df_for_prediction = pd.read_csv(f\"{CFG.data_path}/test.csv\")\n    \n    training_data_df['body_with_url'] = training_data_df['body'].apply(lambda x: x + url_to_semantics(x))\n    training_data_df['input_text'] = training_data_df['rule'] + \"[SEP]\" + training_data_df['body_with_url']\n\n    tokenizer = AutoTokenizer.from_pretrained(CFG.model_name_or_path)\n    train_encodings = tokenizer(training_data_df['input_text'].tolist(), truncation=True, padding=True, max_length=CFG.MAX_LENGTH)\n    train_labels = training_data_df['rule_violation'].tolist()\n    train_dataset = JigsawDataset(train_encodings, train_labels)\n\n    model = AutoModelForSequenceClassification.from_pretrained(CFG.model_name_or_path, num_labels=2)\n    \n    training_args = TrainingArguments(\n        output_dir=CFG.output_dir,\n        num_train_epochs=CFG.EPOCHS,\n        learning_rate=CFG.LEARNING_RATE,\n        per_device_train_batch_size=CFG.BATCH_SIZE,\n        warmup_ratio=0.1,\n        weight_decay=0.01,\n        report_to=\"none\",\n        save_strategy=\"no\",  #这一行加上这个 save_strategy=\"no\"\n        logging_steps=1,\n    )\n    \n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n    )\n    \n    trainer.train()\n\n    test_df_for_prediction['body_with_url'] = test_df_for_prediction['body'].apply(lambda x: x + url_to_semantics(x))\n    test_df_for_prediction['input_text'] = test_df_for_prediction['rule'] + \"[SEP]\" + test_df_for_prediction['body_with_url']\n    \n    test_encodings = tokenizer(test_df_for_prediction['input_text'].tolist(), truncation=True, padding=True, max_length=CFG.MAX_LENGTH)\n    test_dataset = JigsawDataset(test_encodings)\n    \n    predictions = trainer.predict(test_dataset)\n    probs = torch.nn.functional.softmax(torch.tensor(predictions.predictions), dim=1)[:, 1].numpy()\n\n    submission_df = pd.DataFrame({\n        \"row_id\": test_df_for_prediction[\"row_id\"],\n        \"rule_violation\": probs\n    })\n    submission_df.to_csv(\"submission_distilroberta.csv\", index=False)\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T04:00:16.354345Z","iopub.execute_input":"2025-09-23T04:00:16.355163Z","iopub.status.idle":"2025-09-23T04:00:16.367994Z","shell.execute_reply.started":"2025-09-23T04:00:16.355134Z","shell.execute_reply":"2025-09-23T04:00:16.367224Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python train_distilroberta.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T04:00:20.500299Z","iopub.execute_input":"2025-09-23T04:00:20.500953Z","iopub.status.idle":"2025-09-23T04:19:31.135987Z","shell.execute_reply.started":"2025-09-23T04:00:20.500929Z","shell.execute_reply":"2025-09-23T04:19:31.135279Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile train_deberta_auc.py\nimport os\nimport pandas as pd\nimport torch\nimport random\nimport numpy as np\nfrom sklearn.model_selection import train_test_split \nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    Trainer,\n    TrainingArguments\n)\n\nfrom utils import get_dataframe_to_train, url_to_semantics\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed) \n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nclass CFG:\n    model_name_or_path = \"/kaggle/input/huggingfacedebertav3variants/deberta-v3-base\"\n    data_path = \"/kaggle/input/jigsaw-agile-community-rules/\"\n    output_dir = \"./deberta_v3_small_final_model\"\n  \n    EPOCHS = 3\n    LEARNING_RATE = 4e-5  \n    \n    MAX_LENGTH = 512\n    BATCH_SIZE = 12\n\nclass JigsawDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels=None):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        if self.labels:\n            item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.encodings['input_ids'])\n\ndef main():\n    seed_everything(42)\n    training_data_df = get_dataframe_to_train(CFG.data_path)\n    # training_data_df, valid_df = train_test_split(full_df,test_size=0.2,stratify=full_df['rule'],random_state=42)\n    print(f\"Training dataset (from examples only) size: {len(training_data_df)}\")\n\n    test_df_for_prediction = pd.read_csv(f\"{CFG.data_path}/test.csv\")\n    \n    training_data_df['body_with_url'] = training_data_df['body'].apply(lambda x: x + url_to_semantics(x))\n    training_data_df['input_text'] = training_data_df['rule'] + \"[SEP]\" + training_data_df['body_with_url']\n\n    tokenizer = AutoTokenizer.from_pretrained(CFG.model_name_or_path)\n    train_encodings = tokenizer(training_data_df['input_text'].tolist(), truncation=True, padding=True, max_length=CFG.MAX_LENGTH)\n    train_labels = training_data_df['rule_violation'].tolist()\n    train_dataset = JigsawDataset(train_encodings, train_labels)\n\n    model = AutoModelForSequenceClassification.from_pretrained(CFG.model_name_or_path, num_labels=2)\n    \n    training_args = TrainingArguments(\n        output_dir=CFG.output_dir,\n        num_train_epochs=CFG.EPOCHS,\n        learning_rate=CFG.LEARNING_RATE,\n        per_device_train_batch_size=CFG.BATCH_SIZE,\n        warmup_ratio=0.1,\n        weight_decay=0.01,\n        report_to=\"none\",\n        save_strategy=\"no\",  #这一行加上这个 save_strategy=\"no\"\n        logging_steps=1,\n    )\n    \n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n    )\n    \n    trainer.train()\n\n    test_df_for_prediction['body_with_url'] = test_df_for_prediction['body'].apply(lambda x: x + url_to_semantics(x))\n    test_df_for_prediction['input_text'] = test_df_for_prediction['rule'] + \"[SEP]\" + test_df_for_prediction['body_with_url']\n    \n    test_encodings = tokenizer(test_df_for_prediction['input_text'].tolist(), truncation=True, padding=True, max_length=CFG.MAX_LENGTH)\n    test_dataset = JigsawDataset(test_encodings)\n    \n    predictions = trainer.predict(test_dataset)\n    probs = torch.nn.functional.softmax(torch.tensor(predictions.predictions), dim=1)[:, 1].numpy()\n\n    submission_df = pd.DataFrame({\n        \"row_id\": test_df_for_prediction[\"row_id\"],\n        \"rule_violation\": probs\n    })\n    submission_df.to_csv(\"submission_debertaauc.csv\", index=False)\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python train_deberta_auc.py","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pandas as pd","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile constants.py\nEMBDEDDING_MODEL_PATH = \"/kaggle/input/qwen-3-embedding/transformers/0.6b/1\"\nMODEL_OUTPUT_PATH = '/kaggle/input/qwen3-8b-embedding'\nDATA_PATH = \"/kaggle/input/jigsaw-agile-community-rules\"\n\n# https://huggingface.co/Qwen/Qwen3-Embedding-0.6B/blob/main/config_sentence_transformers.json\nEMBEDDING_MODEL_QUERY = \"Instruct: Given a web search query, retrieve relevant passages that answer the query\\nQuery:\"\n\nCLEAN_TEXT = True\nTOP_K = 2000\nBATCH_SIZE = 128","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile utils.py\nimport pandas as pd\nimport torch.distributed as dist\n\nfrom datasets import Dataset\nfrom cleantext import clean\nfrom tqdm.auto import tqdm\n\nfrom constants import CLEAN_TEXT\n\n\ndef build_prompt(row):\n    return f\"\"\"r/{row[\"subreddit\"]}\\nComment: {row[\"body\"]}\"\"\"\n\n\ndef cleaner(text):\n    return clean(\n        text,\n        fix_unicode=True,\n        to_ascii=True,\n        lower=False,\n        no_line_breaks=False,\n        no_urls=True,\n        no_emails=True,\n        no_phone_numbers=True,\n        no_numbers=False,\n        no_digits=False,\n        no_currency_symbols=False,\n        no_punct=False,\n        replace_with_url=\"<URL>\",\n        replace_with_email=\"<EMAIL>\",\n        replace_with_phone_number=\"<PHONE>\",\n        lang=\"en\",\n    )\n\n\n\ndef get_dataframe_to_train(data_path):\n    train_dataset = pd.read_csv(f\"{data_path}/train.csv\")\n    test_dataset = pd.read_csv(f\"{data_path}/test.csv\").sample(frac=0.6, random_state=42).reset_index(drop=True)\n\n    flatten = []\n    flatten.append(train_dataset[[\"body\", \"rule\", \"subreddit\", \"rule_violation\"]])\n    \n    for violation_type in [\"positive\", \"negative\"]:\n        for i in range(1, 3):\n            sub_dataset = test_dataset[[f\"{violation_type}_example_{i}\", \"rule\", \"subreddit\"]].copy()\n            sub_dataset = sub_dataset.rename(columns={f\"{violation_type}_example_{i}\": \"body\"})\n            sub_dataset[\"rule_violation\"] = 1 if violation_type == \"positive\" else 0\n            flatten.append(sub_dataset)\n\n    dataframe = pd.concat(flatten, axis=0)    \n    dataframe = dataframe.drop_duplicates(ignore_index=True)\n    return dataframe\n\n\ndef prepare_dataframe(dataframe):\n    dataframe[\"prompt\"] = dataframe.apply(build_prompt, axis=1)\n\n    \n    if CLEAN_TEXT:\n        tqdm.pandas(desc=\"cleaner\")\n        dataframe[\"prompt\"] = dataframe[\"prompt\"].progress_apply(cleaner)\n\n    if \"rule_violation\" in dataframe.columns:\n        dataframe[\"rule_violation\"] = dataframe[\"rule_violation\"].map(\n            {\n                1: 1,\n                0: -1,\n            }\n        )\n\n    return dataframe","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile semantic.py\nimport pandas as pd\nfrom transformers import AutoModel, AutoModelForCausalLM, AutoTokenizer\nfrom sentence_transformers import SentenceTransformer\nfrom sentence_transformers.util import semantic_search, dot_score\nfrom tqdm.auto import tqdm\nfrom peft import PeftModel, PeftConfig\n\n\nfrom utils import get_dataframe_to_train, prepare_dataframe\nfrom constants import DATA_PATH, EMBDEDDING_MODEL_PATH, EMBEDDING_MODEL_QUERY, TOP_K, BATCH_SIZE, MODEL_OUTPUT_PATH\n\n\n\ndef get_scores(test_dataframe):\n    corpus_dataframe = get_dataframe_to_train(DATA_PATH)\n    corpus_dataframe = prepare_dataframe(corpus_dataframe)\n    \n    # Load base model\n    model = AutoModelForCausalLM.from_pretrained(EMBDEDDING_MODEL_PATH)\n    tokenizer = AutoTokenizer.from_pretrained(EMBDEDDING_MODEL_PATH)\n    \n    # Load adapter configuration and model\n    adapter_config = PeftConfig.from_pretrained(MODEL_OUTPUT_PATH)\n    lora_model = PeftModel.from_pretrained(model, MODEL_OUTPUT_PATH, config=adapter_config)\n    merged_model = lora_model.merge_and_unload()\n    tokenizer.save_pretrained(\"Qwen3Emb_Finetuned\")\n    merged_model.save_pretrained(\"Qwen3Emb_Finetuned\")\n\n    # 4. Tạo lại SentenceTransformer từ encoder đã merge\n    embedding_model = SentenceTransformer(model_name_or_path=\"Qwen3Emb_Finetuned\", device=\"cuda\")\n\n    print('Done loading model!')\n\n    result = []\n    for rule in tqdm(test_dataframe[\"rule\"].unique(), desc=f\"Generate scores for each rule\"):\n        test_dataframe_part = test_dataframe.query(\"rule == @rule\").reset_index(drop=True)\n        corpus_dataframe_part = corpus_dataframe.query(\"rule == @rule\").reset_index(drop=True)\n        corpus_dataframe_part = corpus_dataframe_part.reset_index(names=\"row_id\")\n        \n        query_embeddings = embedding_model.encode(\n            sentences=test_dataframe_part[\"prompt\"].tolist(),\n            prompt=EMBEDDING_MODEL_QUERY,\n            batch_size=BATCH_SIZE,\n            show_progress_bar=True,\n            convert_to_tensor=True,\n            device=\"cuda\",\n            normalize_embeddings=True,\n        )\n        document_embeddings = embedding_model.encode(\n            sentences=corpus_dataframe_part[\"prompt\"].tolist(),\n            batch_size=BATCH_SIZE,\n            show_progress_bar=True,\n            convert_to_tensor=True,\n            device=\"cuda\",\n            normalize_embeddings=True,\n        )\n        test_dataframe_part[\"semantic\"] = semantic_search(\n            query_embeddings,\n            document_embeddings,\n            top_k=TOP_K,\n            score_function=dot_score,\n        )\n        def get_score(semantic):\n            semantic = pd.DataFrame(semantic)\n            semantic = semantic.merge(\n                corpus_dataframe_part[[\"row_id\", \"rule_violation\"]],\n                how=\"left\",\n                left_on=\"corpus_id\",\n                right_on=\"row_id\",\n            )\n            semantic[\"score\"] = semantic[\"score\"]*semantic[\"rule_violation\"]\n            return semantic[\"score\"].sum()\n            \n        tqdm.pandas(desc=f\"Add label for {rule=}\")\n        test_dataframe_part[\"rule_violation\"] = test_dataframe_part[\"semantic\"].progress_apply(get_score)\n        result.append(test_dataframe_part[[\"row_id\", \"rule_violation\"]].copy())\n        \n    submission = pd.concat(result, axis=0)\n    return submission\n\n\ndef generate_submission():\n    test_dataframe = pd.read_csv(f\"{DATA_PATH}/test.csv\")\n    test_dataframe = prepare_dataframe(test_dataframe)\n    \n    submission = get_scores(test_dataframe)\n    submission = test_dataframe[[\"row_id\"]].merge(submission, on=\"row_id\", how=\"left\")\n    submission.to_csv(\"submission_qwen3.csv\", index=False)\n\n\nif __name__ == \"__main__\":\n    generate_submission()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python semantic.py","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile infer_qwen.py\n\nimport os\nimport pandas as pd\nfrom logits_processor_zoo.vllm import MultipleChoiceLogitsProcessor\nimport torch\nimport vllm\nimport numpy as np\nfrom vllm.lora.request import LoRARequest\nimport argparse\nfrom scipy.special import softmax\ndf = pd.read_csv(\"/kaggle/input/jigsaw-agile-community-rules/test.csv\")\n\nMODEL_NAME = \"/kaggle/input/qwen2.5/transformers/14b-instruct-gptq-int4/1\"\nLORA_PATH = \"/kaggle/input/lora_14b_gptq_1epoch_r32/keras/default/1\"\nif __name__=='__main__':\n    os.environ[\"VLLM_USE_V1\"] = \"0\"\n\n    llm = vllm.LLM(\n        MODEL_NAME,\n        # quantization='awq',\n        quantization='gptq',\n        tensor_parallel_size=torch.cuda.device_count(),\n        gpu_memory_utilization=0.98,\n        trust_remote_code=True,\n        dtype=\"half\",\n        enforce_eager=True,\n        max_model_len=2836,\n        disable_log_stats=True,\n        enable_prefix_caching=True,\n        enable_lora=True,\n        max_lora_rank=32\n    )\n    tokenizer = llm.get_tokenizer()\n    SYS_PROMPT = \"\"\"\nYou are given a comment on reddit. Your task is to classify if it violates the given rule. Only respond Yes/No.\n\"\"\"\n    \n    prompts = []\n    for i, row in df.iterrows():\n        text = f\"\"\"\n    r/{row.subreddit}\n    Rule: {row.rule}\n    \n    1) {row.positive_example_1}\n    Violation: Yes\n    \n    2) {row.positive_example_2}\n    Violation: Yes\n    \n    3) {row.negative_example_1}\n    Violation: No\n    \n    4) {row.negative_example_2}\n    Violation: No\n    \n    5) {row.body}\n    \"\"\"\n        \n        messages = [\n            {\"role\": \"system\", \"content\": SYS_PROMPT},\n            {\"role\": \"user\", \"content\": text}\n        ]\n    \n        prompt = tokenizer.apply_chat_template(\n            messages,\n            add_generation_prompt=True,\n            tokenize=False,\n        ) + \"Answer:\"\n        prompts.append(prompt)\n    \n    df[\"prompt\"] = prompts\n    \n    mclp = MultipleChoiceLogitsProcessor(tokenizer, choices=['Yes','No'])\n    outputs = llm.generate(\n        prompts,\n        vllm.SamplingParams(\n            skip_special_tokens=True,\n            max_tokens=1,\n            logits_processors=[mclp],\n            logprobs=2,\n        ),\n        use_tqdm=True,\n        lora_request=LoRARequest(\"default\", 1, LORA_PATH)\n    )\n    logprobs = [\n        {lp.decoded_token: lp.logprob for lp in out.outputs[0].logprobs[0].values()}\n        for out in outputs\n    ]\n    logit_matrix = pd.DataFrame(logprobs)[['Yes','No']]\n    df = pd.concat([df, logit_matrix], axis=1)\n    \n    df[['Yes',\"No\"]] = df[['Yes',\"No\"]].apply(lambda x: softmax(x.values), axis=1, result_type=\"expand\")\n    df[\"pred\"] = df[\"Yes\"]\n    df['rule_violation'] = df[\"pred\"]\n    df[['row_id', 'rule_violation']].to_csv(\"submission_qwen14b.csv\",index=False)\n    pd.read_csv('submission_qwen14b.csv')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python infer_qwen.py","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nq = pd.read_csv('submission_deberta.csv')\nl = pd.read_csv('submission_qwen3.csv')\nm = pd.read_csv('submission_distilroberta.csv')\nw = pd.read_csv('submission_qwen14b.csv')\n#d = pd.read_csv('submission_distilbert.csv')\n#s = pd.read_csv('submission_debertsmall.csv')\na = pd.read_csv('submission_debertaauc.csv')\n\nrq = q['rule_violation'].rank(method='average') / (len(q)+1)\nrl = l['rule_violation'].rank(method='average') / (len(l)+1)\nrm = m['rule_violation'].rank(method='average') / (len(m)+1)\nrw = w['rule_violation'].rank(method='average') / (len(w)+1)\n#rd = d['rule_violation'].rank(method='average') / (len(d)+1)\n#rs = s['rule_violation'].rank(method='average') / (len(s)+1)\nra = a['rule_violation'].rank(method='average') / (len(a)+1)\n\nblend = 0.5*rq + 0.1*rl + 0.1*rm + 0.1*rw + 0.2*ra # or tune the rank-weights with a tiny grid using OOF\nq['rule_violation'] = blend\nq.to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\npd.read_csv('/kaggle/working/submission.csv')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile probe_submission.py\n\nimport pandas as pd\nimport numpy as np\nimport argparse\nimport os\n\ndef run_probe(input_file: str, output_file: str, num_blocks: int, invert_block: int = -1, invert_all: bool = False):\n\n    print(f\"Reading submission file from: {input_file}\")\n    df = pd.read_csv(input_file)\n \n    df['rule_violation'] = pd.to_numeric(df['rule_violation'])\n    \n    n_rows = len(df)\n    print(f\"Total rows: {n_rows}\")\n\n    if invert_all:\n        print(\"Mode: Invert All. Transforming p -> 1-p for all predictions.\")\n        df['rule_violation'] = 1 - df['rule_violation']\n    \n    elif invert_block > 0:\n        if not (1 <= invert_block <= num_blocks):\n            raise ValueError(f\"invert_block must be between 1 and {num_blocks}\")\n            \n        print(f\"Mode: Invert Gain Probe. Testing block {invert_block}/{num_blocks}.\")\n        print(\"Step 1: Inverting all predictions (p -> 1-p).\")\n        df['rule_violation'] = 1 - df['rule_violation']\n        \n        # 计算区块的边界\n        block_size = n_rows / num_blocks\n        start_index = int((invert_block - 1) * block_size)\n        end_index = int(invert_block * block_size) if invert_block < num_blocks else n_rows\n        \n        print(f\"Step 2: Reverting block {invert_block} (indices {start_index} to {end_index-1}) back to original (1-p -> p).\")\n        \n        df.iloc[start_index:end_index, df.columns.get_loc('rule_violation')] = 1 - df.iloc[start_index:end_index]['rule_violation']\n\n    else:\n        print(\"Mode: Standard copy. No transformation applied.\")\n\n    print(f\"Saving probed submission to: {output_file}\")\n    df.to_csv(output_file, index=False)\n    print(\"Done.\")\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Kaggle Submission Probing Tool\")\n    parser.add_argument(\"--input_file\", type=str, required=True, help=\"Path to the baseline submission CSV file.\")\n    parser.add_argument(\"--output_file\", type=str, required=True, help=\"Path to save the new submission CSV file.\")\n    parser.add_argument(\"--num_blocks\", type=int, default=10, help=\"Total number of blocks to split the test set into.\")\n    \n    mode_group = parser.add_mutually_exclusive_group()\n    mode_group.add_argument(\"--invert_all\", action=\"store_true\", help=\"Invert all predictions (p -> 1-p).\")\n    mode_group.add_argument(\"--invert_block\", type=int, default=-1, help=\"The block number (1-based) to revert back to original after a full inversion.\")\n\n    args = parser.parse_args()\n    \n    run_probe(args.input_file, args.output_file, args.num_blocks, args.invert_block, args.invert_all)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T03:05:41.695892Z","iopub.execute_input":"2025-09-23T03:05:41.696122Z","iopub.status.idle":"2025-09-23T03:05:41.702603Z","shell.execute_reply.started":"2025-09-23T03:05:41.696098Z","shell.execute_reply":"2025-09-23T03:05:41.701895Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!python probe_submission.py \\\n#    --input_file submission_qwen3.csv \\\n#    --output_file submission.csv \\\n#    --num_blocks 10 \\\n#    --invert_block 10 ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-23T03:05:41.703301Z","iopub.execute_input":"2025-09-23T03:05:41.703542Z","iopub.status.idle":"2025-09-23T03:05:41.718734Z","shell.execute_reply.started":"2025-09-23T03:05:41.703517Z","shell.execute_reply":"2025-09-23T03:05:41.717857Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}}]}