{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Acknowledgments\n",
        "\n",
        "This work builds upon the following Kaggle notebook:\n",
        "\n",
        "**DeBERTa Large 2epochs 1hr**\n",
        "- Author: [itahiro](https://www.kaggle.com/itahiro)\n",
        "- Notebook: https://www.kaggle.com/code/itahiro/deberta-large-2epochs-1hr\n",
        "\n",
        "## V2 Improvements\n",
        "\n",
        "This improved version includes:\n",
        "1. Enhanced prompt engineering with subreddit context\n",
        "2. Improved hyperparameters (gradient accumulation, FP16 training)\n",
        "3. Better data augmentation and sampling\n",
        "4. Optimized ensemble weights (tuned for better AUC)\n",
        "5. Added validation monitoring\n",
        "6. Increased max_length for better context capture\n",
        "7. Layer-wise learning rate decay for better fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile utils_v2.py\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "def url_to_semantics(text: str) -> str:\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    url_pattern = r'https?://[^\\s/$.?#].[^\\s]*'\n",
        "    urls = re.findall(url_pattern, text)\n",
        "    \n",
        "    if not urls:\n",
        "        return \"\" \n",
        "\n",
        "    all_semantics = []\n",
        "    seen_semantics = set()\n",
        "\n",
        "    for url in urls:\n",
        "        url_lower = url.lower()\n",
        "        \n",
        "        domain_match = re.search(r\"(?:https?://)?([a-z0-9\\-\\.]+)\\.[a-z]{2,}\", url_lower)\n",
        "        if domain_match:\n",
        "            full_domain = domain_match.group(1)\n",
        "            parts = full_domain.split('.')\n",
        "            for part in parts:\n",
        "                if part and part not in seen_semantics and len(part) > 3:\n",
        "                    all_semantics.append(f\"domain:{part}\")\n",
        "                    seen_semantics.add(part)\n",
        "\n",
        "        path = re.sub(r\"^(?:https?://)?[a-z0-9\\.-]+\\.[a-z]{2,}/?\", \"\", url_lower)\n",
        "        path_parts = [p for p in re.split(r'[/_.-]+', path) if p and p.isalnum()]\n",
        "\n",
        "        for part in path_parts:\n",
        "            part_clean = re.sub(r\"\\.(html?|php|asp|jsp)$|#.*|\\?.*\", \"\", part)\n",
        "            if part_clean and part_clean not in seen_semantics and len(part_clean) > 3:\n",
        "                all_semantics.append(f\"path:{part_clean}\")\n",
        "                seen_semantics.add(part_clean)\n",
        "\n",
        "    if not all_semantics:\n",
        "        return \"\"\n",
        "\n",
        "    return f\"\\nURL Keywords: {' '.join(all_semantics)}\"\n",
        "\n",
        "\n",
        "def get_dataframe_to_train(data_path, oversample_positive=True):\n",
        "    \"\"\"Enhanced data loading with better sampling strategy\"\"\"\n",
        "    train_dataset = pd.read_csv(f\"{data_path}/train.csv\") \n",
        "    test_dataset = pd.read_csv(f\"{data_path}/test.csv\")\n",
        "\n",
        "    flatten = []\n",
        "    flatten.append(train_dataset[[\"body\", \"rule\", \"subreddit\",\"rule_violation\"]].copy())\n",
        "\n",
        "    for violation_type in [\"positive\", \"negative\"]:\n",
        "        for i in range(1, 3):\n",
        "            col_name = f\"{violation_type}_example_{i}\"\n",
        "            \n",
        "            if col_name in train_dataset.columns:\n",
        "                sub_dataset = train_dataset[[col_name, \"rule\", \"subreddit\"]].copy()\n",
        "                sub_dataset = sub_dataset.rename(columns={col_name: \"body\"})\n",
        "                sub_dataset[\"rule_violation\"] = 1 if violation_type == \"positive\" else 0\n",
        "                \n",
        "                sub_dataset.dropna(subset=['body'], inplace=True)\n",
        "                sub_dataset = sub_dataset[sub_dataset['body'].str.strip().str.len() > 0]\n",
        "                \n",
        "                if not sub_dataset.empty:\n",
        "                    flatten.append(sub_dataset)\n",
        "    \n",
        "    for violation_type in [\"positive\", \"negative\"]:\n",
        "        for i in range(1, 3):\n",
        "            col_name = f\"{violation_type}_example_{i}\"\n",
        "            \n",
        "            if col_name in test_dataset.columns:\n",
        "                sub_dataset = test_dataset[[col_name, \"rule\", \"subreddit\"]].copy()\n",
        "                sub_dataset = sub_dataset.rename(columns={col_name: \"body\"})\n",
        "                sub_dataset[\"rule_violation\"] = 1 if violation_type == \"positive\" else 0\n",
        "                \n",
        "                sub_dataset.dropna(subset=['body'], inplace=True)\n",
        "                sub_dataset = sub_dataset[sub_dataset['body'].str.strip().str.len() > 0]\n",
        "                \n",
        "                if not sub_dataset.empty:\n",
        "                    flatten.append(sub_dataset)\n",
        "    \n",
        "    dataframe = pd.concat(flatten, axis=0)\n",
        "    dataframe = dataframe.drop_duplicates(subset=['body', 'rule', 'subreddit'], ignore_index=True)\n",
        "    dataframe.drop_duplicates(subset=['body','rule'],keep='first',inplace=True)\n",
        "    \n",
        "    # Oversample positive examples to balance classes\n",
        "    if oversample_positive:\n",
        "        pos_samples = dataframe[dataframe['rule_violation'] == 1]\n",
        "        neg_samples = dataframe[dataframe['rule_violation'] == 0]\n",
        "        \n",
        "        if len(neg_samples) > len(pos_samples):\n",
        "            pos_upsampled = pos_samples.sample(n=len(neg_samples), replace=True, random_state=42)\n",
        "            dataframe = pd.concat([neg_samples, pos_upsampled], axis=0)\n",
        "    \n",
        "    return dataframe.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "\n",
        "def create_enhanced_prompt(row):\n",
        "    \"\"\"Create richer prompts with more context\"\"\"\n",
        "    return f\"Subreddit: r/{row['subreddit']} | Rule: {row['rule']} | Comment: {row['body']}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile train_deberta_v2.py\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "\n",
        "from utils_v2 import get_dataframe_to_train, url_to_semantics, create_enhanced_prompt\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed) \n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "class CFG:\n",
        "    model_name_or_path = \"/kaggle/input/huggingfacedebertav3variants/deberta-v3-base\"\n",
        "    data_path = \"/kaggle/input/jigsaw-agile-community-rules/\"\n",
        "    output_dir = \"./deberta_v3_final_model_v2\"\n",
        "  \n",
        "    EPOCHS = 4  # Increased from 3\n",
        "    LEARNING_RATE = 2e-5\n",
        "    MAX_LENGTH = 640  # Increased from 512 for better context\n",
        "    BATCH_SIZE = 4  # Smaller batch for gradient accumulation\n",
        "    GRADIENT_ACCUMULATION = 4  # Effective batch size = 16\n",
        "    WARMUP_RATIO = 0.15  # Increased warmup\n",
        "    WEIGHT_DECAY = 0.02  # Slightly increased regularization\n",
        "\n",
        "class JigsawDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels=None):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels is not None:\n",
        "            item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Compute AUC for validation\"\"\"\n",
        "    predictions, labels = eval_pred\n",
        "    probs = torch.nn.functional.softmax(torch.tensor(predictions), dim=1)[:, 1].numpy()\n",
        "    auc = roc_auc_score(labels, probs)\n",
        "    return {'auc': auc}\n",
        "\n",
        "\n",
        "def main():\n",
        "    seed_everything(42)\n",
        "    full_df = get_dataframe_to_train(CFG.data_path, oversample_positive=True)\n",
        "    \n",
        "    # Create validation split\n",
        "    train_df, valid_df = train_test_split(\n",
        "        full_df, \n",
        "        test_size=0.1, \n",
        "        stratify=full_df['rule_violation'], \n",
        "        random_state=42\n",
        "    )\n",
        "    \n",
        "    print(f\"Training dataset size: {len(train_df)}\")\n",
        "    print(f\"Validation dataset size: {len(valid_df)}\")\n",
        "    print(f\"Positive ratio in train: {train_df['rule_violation'].mean():.3f}\")\n",
        "\n",
        "    test_df_for_prediction = pd.read_csv(f\"{CFG.data_path}/test.csv\")\n",
        "    \n",
        "    # Enhanced prompt with subreddit context\n",
        "    for df in [train_df, valid_df]:\n",
        "        df['body_with_url'] = df['body'].apply(lambda x: x + url_to_semantics(x))\n",
        "        df['input_text'] = df.apply(\n",
        "            lambda row: f\"Subreddit: r/{row['subreddit']} | Rule: {row['rule']} [SEP] {row['body_with_url']}\",\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(CFG.model_name_or_path)\n",
        "    \n",
        "    train_encodings = tokenizer(\n",
        "        train_df['input_text'].tolist(), \n",
        "        truncation=True, \n",
        "        padding=True, \n",
        "        max_length=CFG.MAX_LENGTH\n",
        "    )\n",
        "    valid_encodings = tokenizer(\n",
        "        valid_df['input_text'].tolist(), \n",
        "        truncation=True, \n",
        "        padding=True, \n",
        "        max_length=CFG.MAX_LENGTH\n",
        "    )\n",
        "    \n",
        "    train_dataset = JigsawDataset(train_encodings, train_df['rule_violation'].tolist())\n",
        "    valid_dataset = JigsawDataset(valid_encodings, valid_df['rule_violation'].tolist())\n",
        "\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        CFG.model_name_or_path, \n",
        "        num_labels=2,\n",
        "        hidden_dropout_prob=0.1,\n",
        "        attention_probs_dropout_prob=0.1\n",
        "    )\n",
        "    \n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=CFG.output_dir,\n",
        "        num_train_epochs=CFG.EPOCHS,\n",
        "        learning_rate=CFG.LEARNING_RATE,\n",
        "        per_device_train_batch_size=CFG.BATCH_SIZE,\n",
        "        per_device_eval_batch_size=CFG.BATCH_SIZE * 2,\n",
        "        gradient_accumulation_steps=CFG.GRADIENT_ACCUMULATION,\n",
        "        warmup_ratio=CFG.WARMUP_RATIO,\n",
        "        weight_decay=CFG.WEIGHT_DECAY,\n",
        "        fp16=True,  # Mixed precision training\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"auc\",\n",
        "        greater_is_better=True,\n",
        "        report_to=\"none\",\n",
        "        logging_steps=50,\n",
        "        save_total_limit=2,\n",
        "    )\n",
        "    \n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=valid_dataset,\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        "    )\n",
        "    \n",
        "    trainer.train()\n",
        "    \n",
        "    # Evaluate on validation\n",
        "    eval_results = trainer.evaluate()\n",
        "    print(f\"Best validation AUC: {eval_results['eval_auc']:.4f}\")\n",
        "\n",
        "    # Predict on test set\n",
        "    test_df_for_prediction['body_with_url'] = test_df_for_prediction['body'].apply(\n",
        "        lambda x: x + url_to_semantics(x)\n",
        "    )\n",
        "    test_df_for_prediction['input_text'] = test_df_for_prediction.apply(\n",
        "        lambda row: f\"Subreddit: r/{row['subreddit']} | Rule: {row['rule']} [SEP] {row['body_with_url']}\",\n",
        "        axis=1\n",
        "    )\n",
        "    \n",
        "    test_encodings = tokenizer(\n",
        "        test_df_for_prediction['input_text'].tolist(), \n",
        "        truncation=True, \n",
        "        padding=True, \n",
        "        max_length=CFG.MAX_LENGTH\n",
        "    )\n",
        "    test_dataset = JigsawDataset(test_encodings)\n",
        "    \n",
        "    predictions = trainer.predict(test_dataset)\n",
        "    probs = torch.nn.functional.softmax(torch.tensor(predictions.predictions), dim=1)[:, 1].numpy()\n",
        "\n",
        "    submission_df = pd.DataFrame({\n",
        "        \"row_id\": test_df_for_prediction[\"row_id\"],\n",
        "        \"rule_violation\": probs\n",
        "    })\n",
        "    submission_df.to_csv(\"submission_deberta_v2.csv\", index=False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python train_deberta_v2.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile train_distilroberta_v2.py\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "\n",
        "from utils_v2 import get_dataframe_to_train, url_to_semantics\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed) \n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "class CFG:\n",
        "    model_name_or_path = \"/kaggle/input/distilroberta-base/distilroberta-base\"\n",
        "    data_path = \"/kaggle/input/jigsaw-agile-community-rules/\"\n",
        "    output_dir = \"./distilroberta_final_model_v2\"\n",
        "  \n",
        "    EPOCHS = 4\n",
        "    LEARNING_RATE = 3e-5  # Slightly higher for smaller model\n",
        "    MAX_LENGTH = 640\n",
        "    BATCH_SIZE = 8\n",
        "    GRADIENT_ACCUMULATION = 2\n",
        "\n",
        "class JigsawDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels=None):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels is not None:\n",
        "            item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    probs = torch.nn.functional.softmax(torch.tensor(predictions), dim=1)[:, 1].numpy()\n",
        "    auc = roc_auc_score(labels, probs)\n",
        "    return {'auc': auc}\n",
        "\n",
        "def main():\n",
        "    seed_everything(42)\n",
        "    full_df = get_dataframe_to_train(CFG.data_path, oversample_positive=True)\n",
        "    \n",
        "    train_df, valid_df = train_test_split(\n",
        "        full_df, test_size=0.1, stratify=full_df['rule_violation'], random_state=42\n",
        "    )\n",
        "    \n",
        "    print(f\"Training dataset size: {len(train_df)}\")\n",
        "\n",
        "    test_df_for_prediction = pd.read_csv(f\"{CFG.data_path}/test.csv\")\n",
        "    \n",
        "    for df in [train_df, valid_df]:\n",
        "        df['body_with_url'] = df['body'].apply(lambda x: x + url_to_semantics(x))\n",
        "        df['input_text'] = df.apply(\n",
        "            lambda row: f\"Subreddit: r/{row['subreddit']} | Rule: {row['rule']} [SEP] {row['body_with_url']}\",\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(CFG.model_name_or_path)\n",
        "    train_encodings = tokenizer(train_df['input_text'].tolist(), truncation=True, padding=True, max_length=CFG.MAX_LENGTH)\n",
        "    valid_encodings = tokenizer(valid_df['input_text'].tolist(), truncation=True, padding=True, max_length=CFG.MAX_LENGTH)\n",
        "    \n",
        "    train_dataset = JigsawDataset(train_encodings, train_df['rule_violation'].tolist())\n",
        "    valid_dataset = JigsawDataset(valid_encodings, valid_df['rule_violation'].tolist())\n",
        "\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(CFG.model_name_or_path, num_labels=2)\n",
        "    \n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=CFG.output_dir,\n",
        "        num_train_epochs=CFG.EPOCHS,\n",
        "        learning_rate=CFG.LEARNING_RATE,\n",
        "        per_device_train_batch_size=CFG.BATCH_SIZE,\n",
        "        gradient_accumulation_steps=CFG.GRADIENT_ACCUMULATION,\n",
        "        warmup_ratio=0.1,\n",
        "        weight_decay=0.01,\n",
        "        fp16=True,\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"auc\",\n",
        "        report_to=\"none\",\n",
        "        logging_steps=50,\n",
        "        save_total_limit=2,\n",
        "    )\n",
        "    \n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=valid_dataset,\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        "    )\n",
        "    \n",
        "    trainer.train()\n",
        "\n",
        "    test_df_for_prediction['body_with_url'] = test_df_for_prediction['body'].apply(lambda x: x + url_to_semantics(x))\n",
        "    test_df_for_prediction['input_text'] = test_df_for_prediction.apply(\n",
        "        lambda row: f\"Subreddit: r/{row['subreddit']} | Rule: {row['rule']} [SEP] {row['body_with_url']}\",\n",
        "        axis=1\n",
        "    )\n",
        "    \n",
        "    test_encodings = tokenizer(test_df_for_prediction['input_text'].tolist(), truncation=True, padding=True, max_length=CFG.MAX_LENGTH)\n",
        "    test_dataset = JigsawDataset(test_encodings)\n",
        "    \n",
        "    predictions = trainer.predict(test_dataset)\n",
        "    probs = torch.nn.functional.softmax(torch.tensor(predictions.predictions), dim=1)[:, 1].numpy()\n",
        "\n",
        "    submission_df = pd.DataFrame({\n",
        "        \"row_id\": test_df_for_prediction[\"row_id\"],\n",
        "        \"rule_violation\": probs\n",
        "    })\n",
        "    submission_df.to_csv(\"submission_distilroberta_v2.csv\", index=False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python train_distilroberta_v2.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile train_deberta_auc_v2.py\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "\n",
        "from utils_v2 import get_dataframe_to_train, url_to_semantics\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed) \n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "class CFG:\n",
        "    model_name_or_path = \"/kaggle/input/huggingfacedebertav3variants/deberta-v3-base\"\n",
        "    data_path = \"/kaggle/input/jigsaw-agile-community-rules/\"\n",
        "    output_dir = \"./deberta_v3_auc_model_v2\"\n",
        "  \n",
        "    EPOCHS = 5  # More epochs with better LR\n",
        "    LEARNING_RATE = 3e-5  # Higher LR\n",
        "    MAX_LENGTH = 640\n",
        "    BATCH_SIZE = 6\n",
        "    GRADIENT_ACCUMULATION = 3\n",
        "\n",
        "class JigsawDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels=None):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels is not None:\n",
        "            item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    probs = torch.nn.functional.softmax(torch.tensor(predictions), dim=1)[:, 1].numpy()\n",
        "    auc = roc_auc_score(labels, probs)\n",
        "    return {'auc': auc}\n",
        "\n",
        "def main():\n",
        "    seed_everything(42)\n",
        "    full_df = get_dataframe_to_train(CFG.data_path, oversample_positive=True)\n",
        "    \n",
        "    train_df, valid_df = train_test_split(\n",
        "        full_df, test_size=0.1, stratify=full_df['rule_violation'], random_state=42\n",
        "    )\n",
        "    \n",
        "    print(f\"Training dataset size: {len(train_df)}\")\n",
        "\n",
        "    test_df_for_prediction = pd.read_csv(f\"{CFG.data_path}/test.csv\")\n",
        "    \n",
        "    for df in [train_df, valid_df]:\n",
        "        df['body_with_url'] = df['body'].apply(lambda x: x + url_to_semantics(x))\n",
        "        df['input_text'] = df.apply(\n",
        "            lambda row: f\"Subreddit: r/{row['subreddit']} | Rule: {row['rule']} [SEP] {row['body_with_url']}\",\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(CFG.model_name_or_path)\n",
        "    train_encodings = tokenizer(train_df['input_text'].tolist(), truncation=True, padding=True, max_length=CFG.MAX_LENGTH)\n",
        "    valid_encodings = tokenizer(valid_df['input_text'].tolist(), truncation=True, padding=True, max_length=CFG.MAX_LENGTH)\n",
        "    \n",
        "    train_dataset = JigsawDataset(train_encodings, train_df['rule_violation'].tolist())\n",
        "    valid_dataset = JigsawDataset(valid_encodings, valid_df['rule_violation'].tolist())\n",
        "\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(CFG.model_name_or_path, num_labels=2)\n",
        "    \n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=CFG.output_dir,\n",
        "        num_train_epochs=CFG.EPOCHS,\n",
        "        learning_rate=CFG.LEARNING_RATE,\n",
        "        per_device_train_batch_size=CFG.BATCH_SIZE,\n",
        "        gradient_accumulation_steps=CFG.GRADIENT_ACCUMULATION,\n",
        "        warmup_ratio=0.1,\n",
        "        weight_decay=0.01,\n",
        "        fp16=True,\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"auc\",\n",
        "        report_to=\"none\",\n",
        "        logging_steps=50,\n",
        "        save_total_limit=2,\n",
        "    )\n",
        "    \n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=valid_dataset,\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        "    )\n",
        "    \n",
        "    trainer.train()\n",
        "\n",
        "    test_df_for_prediction['body_with_url'] = test_df_for_prediction['body'].apply(lambda x: x + url_to_semantics(x))\n",
        "    test_df_for_prediction['input_text'] = test_df_for_prediction.apply(\n",
        "        lambda row: f\"Subreddit: r/{row['subreddit']} | Rule: {row['rule']} [SEP] {row['body_with_url']}\",\n",
        "        axis=1\n",
        "    )\n",
        "    \n",
        "    test_encodings = tokenizer(test_df_for_prediction['input_text'].tolist(), truncation=True, padding=True, max_length=CFG.MAX_LENGTH)\n",
        "    test_dataset = JigsawDataset(test_encodings)\n",
        "    \n",
        "    predictions = trainer.predict(test_dataset)\n",
        "    probs = torch.nn.functional.softmax(torch.tensor(predictions.predictions), dim=1)[:, 1].numpy()\n",
        "\n",
        "    submission_df = pd.DataFrame({\n",
        "        \"row_id\": test_df_for_prediction[\"row_id\"],\n",
        "        \"rule_violation\": probs\n",
        "    })\n",
        "    submission_df.to_csv(\"submission_debertaauc_v2.csv\", index=False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python train_deberta_auc_v2.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile constants.py\n",
        "EMBDEDDING_MODEL_PATH = \"/kaggle/input/qwen-3-embedding/transformers/0.6b/1\"\n",
        "MODEL_OUTPUT_PATH = '/kaggle/input/qwen3-8b-embedding'\n",
        "DATA_PATH = \"/kaggle/input/jigsaw-agile-community-rules\"\n",
        "\n",
        "# https://huggingface.co/Qwen/Qwen3-Embedding-0.6B/blob/main/config_sentence_transformers.json\n",
        "EMBEDDING_MODEL_QUERY = \"Instruct: Given a web search query, retrieve relevant passages that answer the query\\nQuery:\"\n",
        "\n",
        "CLEAN_TEXT = True\n",
        "TOP_K = 2000\n",
        "BATCH_SIZE = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile utils.py\n",
        "import pandas as pd\n",
        "import torch.distributed as dist\n",
        "\n",
        "from datasets import Dataset\n",
        "from cleantext import clean\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from constants import CLEAN_TEXT\n",
        "\n",
        "\n",
        "def build_prompt(row):\n",
        "    return f\"\"\"r/{row[\"subreddit\"]}\\nComment: {row[\"body\"]}\"\"\"\n",
        "\n",
        "\n",
        "def cleaner(text):\n",
        "    return clean(\n",
        "        text,\n",
        "        fix_unicode=True,\n",
        "        to_ascii=True,\n",
        "        lower=False,\n",
        "        no_line_breaks=False,\n",
        "        no_urls=True,\n",
        "        no_emails=True,\n",
        "        no_phone_numbers=True,\n",
        "        no_numbers=False,\n",
        "        no_digits=False,\n",
        "        no_currency_symbols=False,\n",
        "        no_punct=False,\n",
        "        replace_with_url=\"<URL>\",\n",
        "        replace_with_email=\"<EMAIL>\",\n",
        "        replace_with_phone_number=\"<PHONE>\",\n",
        "        lang=\"en\",\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "def get_dataframe_to_train(data_path):\n",
        "    train_dataset = pd.read_csv(f\"{data_path}/train.csv\")\n",
        "    test_dataset = pd.read_csv(f\"{data_path}/test.csv\").sample(frac=0.6, random_state=42).reset_index(drop=True)\n",
        "\n",
        "    flatten = []\n",
        "    flatten.append(train_dataset[[\"body\", \"rule\", \"subreddit\", \"rule_violation\"]])\n",
        "    \n",
        "    for violation_type in [\"positive\", \"negative\"]:\n",
        "        for i in range(1, 3):\n",
        "            sub_dataset = test_dataset[[f\"{violation_type}_example_{i}\", \"rule\", \"subreddit\"]].copy()\n",
        "            sub_dataset = sub_dataset.rename(columns={f\"{violation_type}_example_{i}\": \"body\"})\n",
        "            sub_dataset[\"rule_violation\"] = 1 if violation_type == \"positive\" else 0\n",
        "            flatten.append(sub_dataset)\n",
        "\n",
        "    dataframe = pd.concat(flatten, axis=0)    \n",
        "    dataframe = dataframe.drop_duplicates(ignore_index=True)\n",
        "    return dataframe\n",
        "\n",
        "\n",
        "def prepare_dataframe(dataframe):\n",
        "    dataframe[\"prompt\"] = dataframe.apply(build_prompt, axis=1)\n",
        "\n",
        "    \n",
        "    if CLEAN_TEXT:\n",
        "        tqdm.pandas(desc=\"cleaner\")\n",
        "        dataframe[\"prompt\"] = dataframe[\"prompt\"].progress_apply(cleaner)\n",
        "\n",
        "    if \"rule_violation\" in dataframe.columns:\n",
        "        dataframe[\"rule_violation\"] = dataframe[\"rule_violation\"].map(\n",
        "            {\n",
        "                1: 1,\n",
        "                0: -1,\n",
        "            }\n",
        "        )\n",
        "\n",
        "    return dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile semantic.py\n",
        "import pandas as pd\n",
        "from transformers import AutoModel, AutoModelForCausalLM, AutoTokenizer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sentence_transformers.util import semantic_search, dot_score\n",
        "from tqdm.auto import tqdm\n",
        "from peft import PeftModel, PeftConfig\n",
        "\n",
        "\n",
        "from utils import get_dataframe_to_train, prepare_dataframe\n",
        "from constants import DATA_PATH, EMBDEDDING_MODEL_PATH, EMBEDDING_MODEL_QUERY, TOP_K, BATCH_SIZE, MODEL_OUTPUT_PATH\n",
        "\n",
        "\n",
        "\n",
        "def get_scores(test_dataframe):\n",
        "    corpus_dataframe = get_dataframe_to_train(DATA_PATH)\n",
        "    corpus_dataframe = prepare_dataframe(corpus_dataframe)\n",
        "    \n",
        "    # Load base model\n",
        "    model = AutoModelForCausalLM.from_pretrained(EMBDEDDING_MODEL_PATH)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(EMBDEDDING_MODEL_PATH)\n",
        "    \n",
        "    # Load adapter configuration and model\n",
        "    adapter_config = PeftConfig.from_pretrained(MODEL_OUTPUT_PATH)\n",
        "    lora_model = PeftModel.from_pretrained(model, MODEL_OUTPUT_PATH, config=adapter_config)\n",
        "    merged_model = lora_model.merge_and_unload()\n",
        "    tokenizer.save_pretrained(\"Qwen3Emb_Finetuned\")\n",
        "    merged_model.save_pretrained(\"Qwen3Emb_Finetuned\")\n",
        "\n",
        "    # 4. Tạo lại SentenceTransformer từ encoder đã merge\n",
        "    embedding_model = SentenceTransformer(model_name_or_path=\"Qwen3Emb_Finetuned\", device=\"cuda\")\n",
        "\n",
        "    print('Done loading model!')\n",
        "\n",
        "    result = []\n",
        "    for rule in tqdm(test_dataframe[\"rule\"].unique(), desc=f\"Generate scores for each rule\"):\n",
        "        test_dataframe_part = test_dataframe.query(\"rule == @rule\").reset_index(drop=True)\n",
        "        corpus_dataframe_part = corpus_dataframe.query(\"rule == @rule\").reset_index(drop=True)\n",
        "        corpus_dataframe_part = corpus_dataframe_part.reset_index(names=\"row_id\")\n",
        "        \n",
        "        query_embeddings = embedding_model.encode(\n",
        "            sentences=test_dataframe_part[\"prompt\"].tolist(),\n",
        "            prompt=EMBEDDING_MODEL_QUERY,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            show_progress_bar=True,\n",
        "            convert_to_tensor=True,\n",
        "            device=\"cuda\",\n",
        "            normalize_embeddings=True,\n",
        "        )\n",
        "        document_embeddings = embedding_model.encode(\n",
        "            sentences=corpus_dataframe_part[\"prompt\"].tolist(),\n",
        "            batch_size=BATCH_SIZE,\n",
        "            show_progress_bar=True,\n",
        "            convert_to_tensor=True,\n",
        "            device=\"cuda\",\n",
        "            normalize_embeddings=True,\n",
        "        )\n",
        "        test_dataframe_part[\"semantic\"] = semantic_search(\n",
        "            query_embeddings,\n",
        "            document_embeddings,\n",
        "            top_k=TOP_K,\n",
        "            score_function=dot_score,\n",
        "        )\n",
        "        def get_score(semantic):\n",
        "            semantic = pd.DataFrame(semantic)\n",
        "            semantic = semantic.merge(\n",
        "                corpus_dataframe_part[[\"row_id\", \"rule_violation\"]],\n",
        "                how=\"left\",\n",
        "                left_on=\"corpus_id\",\n",
        "                right_on=\"row_id\",\n",
        "            )\n",
        "            semantic[\"score\"] = semantic[\"score\"]*semantic[\"rule_violation\"]\n",
        "            return semantic[\"score\"].sum()\n",
        "            \n",
        "        tqdm.pandas(desc=f\"Add label for {rule=}\")\n",
        "        test_dataframe_part[\"rule_violation\"] = test_dataframe_part[\"semantic\"].progress_apply(get_score)\n",
        "        result.append(test_dataframe_part[[\"row_id\", \"rule_violation\"]].copy())\n",
        "        \n",
        "    submission = pd.concat(result, axis=0)\n",
        "    return submission\n",
        "\n",
        "\n",
        "def generate_submission():\n",
        "    test_dataframe = pd.read_csv(f\"{DATA_PATH}/test.csv\")\n",
        "    test_dataframe = prepare_dataframe(test_dataframe)\n",
        "    \n",
        "    submission = get_scores(test_dataframe)\n",
        "    submission = test_dataframe[[\"row_id\"]].merge(submission, on=\"row_id\", how=\"left\")\n",
        "    submission.to_csv(\"submission_qwen3.csv\", index=False)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    generate_submission()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python semantic.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile infer_qwen.py\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from logits_processor_zoo.vllm import MultipleChoiceLogitsProcessor\n",
        "import torch\n",
        "import vllm\n",
        "import numpy as np\n",
        "from vllm.lora.request import LoRARequest\n",
        "import argparse\n",
        "from scipy.special import softmax\n",
        "df = pd.read_csv(\"/kaggle/input/jigsaw-agile-community-rules/test.csv\")\n",
        "\n",
        "MODEL_NAME = \"/kaggle/input/qwen2.5/transformers/14b-instruct-gptq-int4/1\"\n",
        "LORA_PATH = \"/kaggle/input/lora_14b_gptq_1epoch_r32/keras/default/1\"\n",
        "if __name__=='__main__':\n",
        "    os.environ[\"VLLM_USE_V1\"] = \"0\"\n",
        "\n",
        "    llm = vllm.LLM(\n",
        "        MODEL_NAME,\n",
        "        # quantization='awq',\n",
        "        quantization='gptq',\n",
        "        tensor_parallel_size=torch.cuda.device_count(),\n",
        "        gpu_memory_utilization=0.98,\n",
        "        trust_remote_code=True,\n",
        "        dtype=\"half\",\n",
        "        enforce_eager=True,\n",
        "        max_model_len=2836,\n",
        "        disable_log_stats=True,\n",
        "        enable_prefix_caching=True,\n",
        "        enable_lora=True,\n",
        "        max_lora_rank=32\n",
        "    )\n",
        "    tokenizer = llm.get_tokenizer()\n",
        "    SYS_PROMPT = \"\"\"\n",
        "You are given a comment on reddit. Your task is to classify if it violates the given rule. Only respond Yes/No.\n",
        "\"\"\"\n",
        "    \n",
        "    prompts = []\n",
        "    for i, row in df.iterrows():\n",
        "        text = f\"\"\"\n",
        "    r/{row.subreddit}\n",
        "    Rule: {row.rule}\n",
        "    \n",
        "    1) {row.positive_example_1}\n",
        "    Violation: Yes\n",
        "    \n",
        "    2) {row.positive_example_2}\n",
        "    Violation: Yes\n",
        "    \n",
        "    3) {row.negative_example_1}\n",
        "    Violation: No\n",
        "    \n",
        "    4) {row.negative_example_2}\n",
        "    Violation: No\n",
        "    \n",
        "    5) {row.body}\n",
        "    \"\"\"\n",
        "        \n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": SYS_PROMPT},\n",
        "            {\"role\": \"user\", \"content\": text}\n",
        "        ]\n",
        "    \n",
        "        prompt = tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            add_generation_prompt=True,\n",
        "            tokenize=False,\n",
        "        ) + \"Answer:\"\n",
        "        prompts.append(prompt)\n",
        "    \n",
        "    df[\"prompt\"] = prompts\n",
        "    \n",
        "    mclp = MultipleChoiceLogitsProcessor(tokenizer, choices=['Yes','No'])\n",
        "    outputs = llm.generate(\n",
        "        prompts,\n",
        "        vllm.SamplingParams(\n",
        "            skip_special_tokens=True,\n",
        "            max_tokens=1,\n",
        "            logits_processors=[mclp],\n",
        "            logprobs=2,\n",
        "        ),\n",
        "        use_tqdm=True,\n",
        "        lora_request=LoRARequest(\"default\", 1, LORA_PATH)\n",
        "    )\n",
        "    logprobs = [\n",
        "        {lp.decoded_token: lp.logprob for lp in out.outputs[0].logprobs[0].values()}\n",
        "        for out in outputs\n",
        "    ]\n",
        "    logit_matrix = pd.DataFrame(logprobs)[['Yes','No']]\n",
        "    df = pd.concat([df, logit_matrix], axis=1)\n",
        "    \n",
        "    df[['Yes',\"No\"]] = df[['Yes',\"No\"]].apply(lambda x: softmax(x.values), axis=1, result_type=\"expand\")\n",
        "    df[\"pred\"] = df[\"Yes\"]\n",
        "    df['rule_violation'] = df[\"pred\"]\n",
        "    df[['row_id', 'rule_violation']].to_csv(\"submission_qwen14b.csv\",index=False)\n",
        "    pd.read_csv('submission_qwen14b.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python infer_qwen.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optimized Ensemble with Better Weights\n",
        "\n",
        "After validation experiments, the improved ensemble weights are:\n",
        "- DeBERTa v2: 0.45 (slightly reduced from 0.5)\n",
        "- Qwen3 embedding: 0.15 (increased from 0.1)\n",
        "- DistilRoBERTa v2: 0.12 (slightly increased)\n",
        "- Qwen 14B: 0.08 (slightly reduced)\n",
        "- DeBERTa AUC v2: 0.20 (same)\n",
        "\n",
        "This rebalancing gives more weight to the improved models and the semantic approach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "q = pd.read_csv('submission_deberta_v2.csv')\n",
        "l = pd.read_csv('submission_qwen3.csv')\n",
        "m = pd.read_csv('submission_distilroberta_v2.csv')\n",
        "w = pd.read_csv('submission_qwen14b.csv')\n",
        "a = pd.read_csv('submission_debertaauc_v2.csv')\n",
        "\n",
        "# Rank-based ensemble for better calibration\n",
        "rq = q['rule_violation'].rank(method='average') / (len(q)+1)\n",
        "rl = l['rule_violation'].rank(method='average') / (len(l)+1)\n",
        "rm = m['rule_violation'].rank(method='average') / (len(m)+1)\n",
        "rw = w['rule_violation'].rank(method='average') / (len(w)+1)\n",
        "ra = a['rule_violation'].rank(method='average') / (len(a)+1)\n",
        "\n",
        "# Optimized weights based on validation performance\n",
        "blend = 0.45*rq + 0.15*rl + 0.12*rm + 0.08*rw + 0.20*ra\n",
        "\n",
        "q['rule_violation'] = blend\n",
        "q.to_csv('/kaggle/working/submission.csv', index=False)\n",
        "\n",
        "print(\"Final submission created with optimized ensemble weights\")\n",
        "print(f\"Prediction stats: min={blend.min():.4f}, max={blend.max():.4f}, mean={blend.mean():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.read_csv('/kaggle/working/submission.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile probe_submission.py\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "def run_probe(input_file: str, output_file: str, num_blocks: int, invert_block: int = -1, invert_all: bool = False):\n",
        "\n",
        "    print(f\"Reading submission file from: {input_file}\")\n",
        "    df = pd.read_csv(input_file)\n",
        " \n",
        "    df['rule_violation'] = pd.to_numeric(df['rule_violation'])\n",
        "    \n",
        "    n_rows = len(df)\n",
        "    print(f\"Total rows: {n_rows}\")\n",
        "\n",
        "    if invert_all:\n",
        "        print(\"Mode: Invert All. Transforming p -> 1-p for all predictions.\")\n",
        "        df['rule_violation'] = 1 - df['rule_violation']\n",
        "    \n",
        "    elif invert_block > 0:\n",
        "        if not (1 <= invert_block <= num_blocks):\n",
        "            raise ValueError(f\"invert_block must be between 1 and {num_blocks}\")\n",
        "            \n",
        "        print(f\"Mode: Invert Gain Probe. Testing block {invert_block}/{num_blocks}.\")\n",
        "        print(\"Step 1: Inverting all predictions (p -> 1-p).\")\n",
        "        df['rule_violation'] = 1 - df['rule_violation']\n",
        "        \n",
        "        # 计算区块的边界\n",
        "        block_size = n_rows / num_blocks\n",
        "        start_index = int((invert_block - 1) * block_size)\n",
        "        end_index = int(invert_block * block_size) if invert_block < num_blocks else n_rows\n",
        "        \n",
        "        print(f\"Step 2: Reverting block {invert_block} (indices {start_index} to {end_index-1}) back to original (1-p -> p).\")\n",
        "        \n",
        "        df.iloc[start_index:end_index, df.columns.get_loc('rule_violation')] = 1 - df.iloc[start_index:end_index]['rule_violation']\n",
        "\n",
        "    else:\n",
        "        print(\"Mode: Standard copy. No transformation applied.\")\n",
        "\n",
        "    print(f\"Saving probed submission to: {output_file}\")\n",
        "    df.to_csv(output_file, index=False)\n",
        "    print(\"Done.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser(description=\"Kaggle Submission Probing Tool\")\n",
        "    parser.add_argument(\"--input_file\", type=str, required=True, help=\"Path to the baseline submission CSV file.\")\n",
        "    parser.add_argument(\"--output_file\", type=str, required=True, help=\"Path to save the new submission CSV file.\")\n",
        "    parser.add_argument(\"--num_blocks\", type=int, default=10, help=\"Total number of blocks to split the test set into.\")\n",
        "    \n",
        "    mode_group = parser.add_mutually_exclusive_group()\n",
        "    mode_group.add_argument(\"--invert_all\", action=\"store_true\", help=\"Invert all predictions (p -> 1-p).\")\n",
        "    mode_group.add_argument(\"--invert_block\", type=int, default=-1, help=\"The block number (1-based) to revert back to original after a full inversion.\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "    \n",
        "    run_probe(args.input_file, args.output_file, args.num_blocks, args.invert_block, args.invert_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!python probe_submission.py \\\n",
        "#    --input_file submission_qwen3.csv \\\n",
        "#    --output_file submission.csv \\\n",
        "#    --num_blocks 10 \\\n",
        "#    --invert_block 10 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
