{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeBERTa Single Model with TTA - Strategy B\n",
    "\n",
    "## Overview\n",
    "Based on experiment analysis, **simple approaches work best**. This notebook focuses on:\n",
    "- Single best model: DeBERTa v3 base\n",
    "- Multiple training runs with different seeds (TTA approach)\n",
    "- Ensemble of the same model trained differently\n",
    "\n",
    "## Strategy: Simplicity + Test-Time Augmentation\n",
    "\n",
    "### Key Insight from Past Experiments:\n",
    "- Experiment 7 (simple DeBERTa, 3 epochs) → **0.917 AUC (best)**\n",
    "- Experiment 9 (optimized DeBERTa, 4 epochs) → 0.916 AUC (worse)\n",
    "- **Lesson**: Simple is better, but can we improve through diversity?\n",
    "\n",
    "### Approach:\n",
    "Train DeBERTa v3 **3 times** with different random seeds:\n",
    "1. Seed 42 (baseline)\n",
    "2. Seed 123\n",
    "3. Seed 456\n",
    "\n",
    "Then ensemble the 3 predictions with equal weighting.\n",
    "\n",
    "### Why This Should Work:\n",
    "- **Same model, different initializations** → Captures different local optima\n",
    "- **Reduces variance** → More stable predictions\n",
    "- **No complexity added** → Keeps training simple (3 epochs, proven config)\n",
    "- **TTA effect** → Similar to test-time augmentation but at training level\n",
    "\n",
    "## Expected Performance\n",
    "- **Target**: 0.918-0.919 AUC\n",
    "- **Rationale**: Seed diversity should reduce variance without adding harmful complexity\n",
    "- **Risk**: Low (same proven approach, just repeated)\n",
    "\n",
    "## Acknowledgments\n",
    "\n",
    "This work builds upon:\n",
    "\n",
    "**Experiment 7: DeBERTa Large 2epochs 1hr (0.917 AUC)**\n",
    "- Author: [itahiro](https://www.kaggle.com/itahiro)\n",
    "- Notebook: https://www.kaggle.com/code/itahiro/deberta-large-2epochs-1hr\n",
    "- Contribution: Proven DeBERTa v3 training configuration, URL semantic extraction\n",
    "\n",
    "**Modification**: Train same model 3x with different seeds for ensemble diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile utils.py\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def url_to_semantics(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    url_pattern = r'https?://[^\\s/$.?#].[^\\s]*'\n",
    "    urls = re.findall(url_pattern, text)\n",
    "    \n",
    "    if not urls:\n",
    "        return \"\" \n",
    "\n",
    "    all_semantics = []\n",
    "    seen_semantics = set()\n",
    "\n",
    "    for url in urls:\n",
    "        url_lower = url.lower()\n",
    "        \n",
    "        domain_match = re.search(r\"(?:https?://)?([a-z0-9\\-\\.]+)\\.[a-z]{2,}\", url_lower)\n",
    "        if domain_match:\n",
    "            full_domain = domain_match.group(1)\n",
    "            parts = full_domain.split('.')\n",
    "            for part in parts:\n",
    "                if part and part not in seen_semantics and len(part) > 3:\n",
    "                    all_semantics.append(f\"domain:{part}\")\n",
    "                    seen_semantics.add(part)\n",
    "\n",
    "        path = re.sub(r\"^(?:https?://)?[a-z0-9\\.-]+\\.[a-z]{2,}/?\", \"\", url_lower)\n",
    "        path_parts = [p for p in re.split(r'[/_.-]+', path) if p and p.isalnum()]\n",
    "\n",
    "        for part in path_parts:\n",
    "            part_clean = re.sub(r\"\\.(html?|php|asp|jsp)$|#.*|\\?.*\", \"\", part)\n",
    "            if part_clean and part_clean not in seen_semantics and len(part_clean) > 3:\n",
    "                all_semantics.append(f\"path:{part_clean}\")\n",
    "                seen_semantics.add(part_clean)\n",
    "\n",
    "    if not all_semantics:\n",
    "        return \"\"\n",
    "\n",
    "    return f\"\\nURL Keywords: {' '.join(all_semantics)}\"\n",
    "\n",
    "\n",
    "def get_dataframe_to_train(data_path):\n",
    "    train_dataset = pd.read_csv(f\"{data_path}/train.csv\") \n",
    "    test_dataset = pd.read_csv(f\"{data_path}/test.csv\")\n",
    "\n",
    "    flatten = []\n",
    "\n",
    "    flatten.append(train_dataset[[\"body\", \"rule\", \"subreddit\",\"rule_violation\"]].copy())\n",
    "\n",
    "    for violation_type in [\"positive\", \"negative\"]:\n",
    "        for i in range(1, 3):\n",
    "            col_name = f\"{violation_type}_example_{i}\"\n",
    "            \n",
    "            if col_name in train_dataset.columns:\n",
    "                sub_dataset = train_dataset[[col_name, \"rule\", \"subreddit\"]].copy()\n",
    "                sub_dataset = sub_dataset.rename(columns={col_name: \"body\"})\n",
    "                sub_dataset[\"rule_violation\"] = 1 if violation_type == \"positive\" else 0\n",
    "                \n",
    "                sub_dataset.dropna(subset=['body'], inplace=True)\n",
    "                sub_dataset = sub_dataset[sub_dataset['body'].str.strip().str.len() > 0]\n",
    "                \n",
    "                if not sub_dataset.empty:\n",
    "                    flatten.append(sub_dataset)\n",
    "    \n",
    "    for violation_type in [\"positive\", \"negative\"]:\n",
    "        for i in range(1, 3):\n",
    "            col_name = f\"{violation_type}_example_{i}\"\n",
    "            \n",
    "            if col_name in test_dataset.columns:\n",
    "                sub_dataset = test_dataset[[col_name, \"rule\", \"subreddit\"]].copy()\n",
    "                sub_dataset = sub_dataset.rename(columns={col_name: \"body\"})\n",
    "                sub_dataset[\"rule_violation\"] = 1 if violation_type == \"positive\" else 0\n",
    "                \n",
    "                sub_dataset.dropna(subset=['body'], inplace=True)\n",
    "                sub_dataset = sub_dataset[sub_dataset['body'].str.strip().str.len() > 0]\n",
    "                \n",
    "                if not sub_dataset.empty:\n",
    "                    flatten.append(sub_dataset)\n",
    "    \n",
    "    dataframe = pd.concat(flatten, axis=0)\n",
    "    dataframe = dataframe.drop_duplicates(subset=['body', 'rule', 'subreddit'], ignore_index=True)\n",
    "    dataframe.drop_duplicates(subset=['body','rule'],keep='first',inplace=True)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile train_deberta_seed.py\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n",
    "\n",
    "from utils import get_dataframe_to_train, url_to_semantics\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "class CFG:\n",
    "    model_name_or_path = \"/kaggle/input/huggingfacedebertav3variants/deberta-v3-base\"\n",
    "    data_path = \"/kaggle/input/jigsaw-agile-community-rules/\"\n",
    "    \n",
    "    # Use Experiment 7's proven config\n",
    "    EPOCHS = 3\n",
    "    LEARNING_RATE = 2e-5  \n",
    "    MAX_LENGTH = 512\n",
    "    BATCH_SIZE = 8\n",
    "\n",
    "class JigsawDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels:\n",
    "            item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "\n",
    "def main(seed, output_suffix):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training with seed: {seed}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    training_data_df = get_dataframe_to_train(CFG.data_path)\n",
    "    # Reshuffle with the new seed\n",
    "    training_data_df = training_data_df.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "    print(f\"Training dataset size: {len(training_data_df)}\")\n",
    "\n",
    "    test_df_for_prediction = pd.read_csv(f\"{CFG.data_path}/test.csv\")\n",
    "    \n",
    "    training_data_df['body_with_url'] = training_data_df['body'].apply(lambda x: x + url_to_semantics(x))\n",
    "    training_data_df['input_text'] = training_data_df['rule'] + \"[SEP]\" + training_data_df['body_with_url']\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(CFG.model_name_or_path)\n",
    "    train_encodings = tokenizer(training_data_df['input_text'].tolist(), truncation=True, padding=True, max_length=CFG.MAX_LENGTH)\n",
    "    train_labels = training_data_df['rule_violation'].tolist()\n",
    "    train_dataset = JigsawDataset(train_encodings, train_labels)\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(CFG.model_name_or_path, num_labels=2)\n",
    "    \n",
    "    output_dir = f\"./deberta_seed_{seed}\"\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=CFG.EPOCHS,\n",
    "        learning_rate=CFG.LEARNING_RATE,\n",
    "        per_device_train_batch_size=CFG.BATCH_SIZE,\n",
    "        warmup_ratio=0.1,\n",
    "        weight_decay=0.01,\n",
    "        report_to=\"none\",\n",
    "        save_strategy=\"no\",\n",
    "        logging_steps=1,\n",
    "        seed=seed,\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "\n",
    "    test_df_for_prediction['body_with_url'] = test_df_for_prediction['body'].apply(lambda x: x + url_to_semantics(x))\n",
    "    test_df_for_prediction['input_text'] = test_df_for_prediction['rule'] + \"[SEP]\" + test_df_for_prediction['body_with_url']\n",
    "    \n",
    "    test_encodings = tokenizer(test_df_for_prediction['input_text'].tolist(), truncation=True, padding=True, max_length=CFG.MAX_LENGTH)\n",
    "    test_dataset = JigsawDataset(test_encodings)\n",
    "    \n",
    "    predictions = trainer.predict(test_dataset)\n",
    "    probs = torch.nn.functional.softmax(torch.tensor(predictions.predictions), dim=1)[:, 1].numpy()\n",
    "\n",
    "    submission_df = pd.DataFrame({\n",
    "        \"row_id\": test_df_for_prediction[\"row_id\"],\n",
    "        \"rule_violation\": probs\n",
    "    })\n",
    "    \n",
    "    output_file = f\"submission_deberta_{output_suffix}.csv\"\n",
    "    submission_df.to_csv(output_file, index=False)\n",
    "    print(f\"\\nSaved predictions to: {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) != 3:\n",
    "        print(\"Usage: python train_deberta_seed.py <seed> <output_suffix>\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    seed = int(sys.argv[1])\n",
    "    output_suffix = sys.argv[2]\n",
    "    main(seed, output_suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with 3 Different Seeds\n",
    "\n",
    "We'll train the same DeBERTa v3 model three times with different random seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with seed 42 (baseline from Experiment 7)\n",
    "!python train_deberta_seed.py 42 seed42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with seed 123\n",
    "!python train_deberta_seed.py 123 seed123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with seed 456\n",
    "!python train_deberta_seed.py 456 seed456"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble the Three Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load all three predictions\n",
    "print(\"Loading predictions from 3 different seeds...\")\n",
    "pred1 = pd.read_csv('submission_deberta_seed42.csv')\n",
    "pred2 = pd.read_csv('submission_deberta_seed123.csv')\n",
    "pred3 = pd.read_csv('submission_deberta_seed456.csv')\n",
    "\n",
    "print(f\"All predictions loaded. Shape: {pred1.shape}\")\n",
    "\n",
    "# Rank normalization\n",
    "def rank_normalize(series):\n",
    "    return series.rank(method='average') / (len(series) + 1)\n",
    "\n",
    "r1 = rank_normalize(pred1['rule_violation'])\n",
    "r2 = rank_normalize(pred2['rule_violation'])\n",
    "r3 = rank_normalize(pred3['rule_violation'])\n",
    "\n",
    "# Equal weight ensemble\n",
    "ensemble = (r1 + r2 + r3) / 3.0\n",
    "\n",
    "print(f\"\\nEnsemble Statistics:\")\n",
    "print(f\"  Mean: {ensemble.mean():.4f}\")\n",
    "print(f\"  Std: {ensemble.std():.4f}\")\n",
    "print(f\"  Min: {ensemble.min():.4f}\")\n",
    "print(f\"  Max: {ensemble.max():.4f}\")\n",
    "\n",
    "# Measure prediction variance across seeds\n",
    "variance = np.var([r1, r2, r3], axis=0).mean()\n",
    "print(f\"  Average variance across seeds: {variance:.6f}\")\n",
    "print(f\"  (Lower is better - means predictions are similar)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final submission\n",
    "submission = pd.DataFrame({\n",
    "    'row_id': pred1['row_id'],\n",
    "    'rule_violation': ensemble\n",
    "})\n",
    "\n",
    "submission.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "\n",
    "print(\"\\n=== Submission Created ===\")\n",
    "print(f\"Saved to: /kaggle/working/submission.csv\")\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "print(submission.head(10))\n",
    "\n",
    "print(\"\\n=== Expected Performance ===\")\n",
    "print(f\"Target: 0.918-0.919 AUC\")\n",
    "print(f\"Rationale: Seed diversity reduces variance without adding complexity\")\n",
    "print(f\"Risk Level: Low (same proven config from Exp 7, just repeated)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook implements a **simple yet effective** improvement strategy:\n",
    "\n",
    "### What We Did:\n",
    "- Used Experiment 7's proven DeBERTa v3 config (3 epochs, LR=2e-5)\n",
    "- Trained 3 times with different seeds (42, 123, 456)\n",
    "- Ensembled with equal weights\n",
    "\n",
    "### Why This Should Work:\n",
    "1. **Proven base**: Experiment 7 scored 0.917 with seed 42\n",
    "2. **Variance reduction**: Different seeds capture different local optima\n",
    "3. **No added complexity**: Same simple training, no over-optimization\n",
    "4. **TTA-like effect**: Training-time augmentation through seed diversity\n",
    "\n",
    "### Philosophy:\n",
    "Sometimes the best improvement is not adding complexity, but adding **diversity** to what already works."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
