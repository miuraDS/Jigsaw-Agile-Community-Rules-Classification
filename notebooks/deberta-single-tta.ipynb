{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeBERTa Single Model with Seed TTA - Complete Implementation\n",
    "\n",
    "## Overview\n",
    "Based on experiment analysis, **simple approaches work best**. This notebook implements:\n",
    "- Single best model: DeBERTa v3 base\n",
    "- Train 3 times with different seeds (42, 123, 456)\n",
    "- Ensemble predictions for variance reduction\n",
    "\n",
    "## Strategy: Simplicity + Diversity\n",
    "\n",
    "### Key Insight from Past Experiments:\n",
    "- Experiment 7 (simple DeBERTa, 3 epochs, seed 42) → **0.917 AUC (BEST)**\n",
    "- Experiment 9 (optimized DeBERTa, 4 epochs) → 0.916 AUC (WORSE)\n",
    "- **Lesson**: Don't change what works, just add diversity\n",
    "\n",
    "### Approach:\n",
    "1. Train DeBERTa v3 with seed 42 (Experiment 7 baseline)\n",
    "2. Train DeBERTa v3 with seed 123\n",
    "3. Train DeBERTa v3 with seed 456\n",
    "4. Ensemble with equal weights\n",
    "\n",
    "### Why This Should Work:\n",
    "- **Same model, different initializations** → Different local optima\n",
    "- **Variance reduction** → More stable predictions\n",
    "- **No complexity** → Exact same training config (3 epochs, proven)\n",
    "- **Low risk** → Just repeating what already works\n",
    "\n",
    "## Expected Performance\n",
    "- **Target**: 0.918-0.919 AUC\n",
    "- **Rationale**: Seed diversity reduces variance\n",
    "- **Risk**: Very Low\n",
    "\n",
    "## Acknowledgments\n",
    "\n",
    "**Experiment 7: DeBERTa Large 2epochs 1hr (0.917 AUC)**\n",
    "- Author: [itahiro](https://www.kaggle.com/itahiro)\n",
    "- Notebook: https://www.kaggle.com/code/itahiro/deberta-large-2epochs-1hr\n",
    "- Contribution: Proven DeBERTa v3 training configuration\n",
    "\n",
    "**Modification**: Train same model 3x with different seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile utils.py\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def url_to_semantics(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    url_pattern = r'https?://[^\\s/$.?#].[^\\s]*'\n",
    "    urls = re.findall(url_pattern, text)\n",
    "    \n",
    "    if not urls:\n",
    "        return \"\" \n",
    "\n",
    "    all_semantics = []\n",
    "    seen_semantics = set()\n",
    "\n",
    "    for url in urls:\n",
    "        url_lower = url.lower()\n",
    "        \n",
    "        domain_match = re.search(r\"(?:https?://)?([a-z0-9\\-\\.]+)\\.[a-z]{2,}\", url_lower)\n",
    "        if domain_match:\n",
    "            full_domain = domain_match.group(1)\n",
    "            parts = full_domain.split('.')\n",
    "            for part in parts:\n",
    "                if part and part not in seen_semantics and len(part) > 3:\n",
    "                    all_semantics.append(f\"domain:{part}\")\n",
    "                    seen_semantics.add(part)\n",
    "\n",
    "        path = re.sub(r\"^(?:https?://)?[a-z0-9\\.-]+\\.[a-z]{2,}/?\", \"\", url_lower)\n",
    "        path_parts = [p for p in re.split(r'[/_.-]+', path) if p and p.isalnum()]\n",
    "\n",
    "        for part in path_parts:\n",
    "            part_clean = re.sub(r\"\\.(html?|php|asp|jsp)$|#.*|\\?.*\", \"\", part)\n",
    "            if part_clean and part_clean not in seen_semantics and len(part_clean) > 3:\n",
    "                all_semantics.append(f\"path:{part_clean}\")\n",
    "                seen_semantics.add(part_clean)\n",
    "\n",
    "    if not all_semantics:\n",
    "        return \"\"\n",
    "\n",
    "    return f\"\\nURL Keywords: {' '.join(all_semantics)}\"\n",
    "\n",
    "\n",
    "def get_dataframe_to_train(data_path):\n",
    "    train_dataset = pd.read_csv(f\"{data_path}/train.csv\") \n",
    "    test_dataset = pd.read_csv(f\"{data_path}/test.csv\")\n",
    "\n",
    "    flatten = []\n",
    "    flatten.append(train_dataset[[\"body\", \"rule\", \"subreddit\",\"rule_violation\"]].copy())\n",
    "\n",
    "    for violation_type in [\"positive\", \"negative\"]:\n",
    "        for i in range(1, 3):\n",
    "            col_name = f\"{violation_type}_example_{i}\"\n",
    "            \n",
    "            if col_name in train_dataset.columns:\n",
    "                sub_dataset = train_dataset[[col_name, \"rule\", \"subreddit\"]].copy()\n",
    "                sub_dataset = sub_dataset.rename(columns={col_name: \"body\"})\n",
    "                sub_dataset[\"rule_violation\"] = 1 if violation_type == \"positive\" else 0\n",
    "                sub_dataset.dropna(subset=['body'], inplace=True)\n",
    "                sub_dataset = sub_dataset[sub_dataset['body'].str.strip().str.len() > 0]\n",
    "                if not sub_dataset.empty:\n",
    "                    flatten.append(sub_dataset)\n",
    "    \n",
    "    for violation_type in [\"positive\", \"negative\"]:\n",
    "        for i in range(1, 3):\n",
    "            col_name = f\"{violation_type}_example_{i}\"\n",
    "            \n",
    "            if col_name in test_dataset.columns:\n",
    "                sub_dataset = test_dataset[[col_name, \"rule\", \"subreddit\"]].copy()\n",
    "                sub_dataset = sub_dataset.rename(columns={col_name: \"body\"})\n",
    "                sub_dataset[\"rule_violation\"] = 1 if violation_type == \"positive\" else 0\n",
    "                sub_dataset.dropna(subset=['body'], inplace=True)\n",
    "                sub_dataset = sub_dataset[sub_dataset['body'].str.strip().str.len() > 0]\n",
    "                if not sub_dataset.empty:\n",
    "                    flatten.append(sub_dataset)\n",
    "    \n",
    "    dataframe = pd.concat(flatten, axis=0)\n",
    "    dataframe = dataframe.drop_duplicates(subset=['body', 'rule', 'subreddit'], ignore_index=True)\n",
    "    dataframe.drop_duplicates(subset=['body','rule'],keep='first',inplace=True)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop with Different Seeds\n",
    "\n",
    "We'll train the same DeBERTa v3 model three times, each with a different seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n",
    "from utils import get_dataframe_to_train, url_to_semantics\n",
    "\n",
    "def seed_everything(seed):\n",
    "    \"\"\"Set all random seeds for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "class CFG:\n",
    "    model_name_or_path = \"/kaggle/input/huggingfacedebertav3variants/deberta-v3-base\"\n",
    "    data_path = \"/kaggle/input/jigsaw-agile-community-rules/\"\n",
    "    \n",
    "    # Experiment 7's proven config - DO NOT CHANGE\n",
    "    EPOCHS = 3\n",
    "    LEARNING_RATE = 2e-5  \n",
    "    MAX_LENGTH = 512\n",
    "    BATCH_SIZE = 8\n",
    "\n",
    "class JigsawDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels:\n",
    "            item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "\n",
    "def train_and_predict(seed, output_suffix):\n",
    "    \"\"\"Train model with given seed and generate predictions\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Training with seed: {seed}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    seed_everything(seed)\n",
    "    \n",
    "    # Load and prepare training data\n",
    "    training_data_df = get_dataframe_to_train(CFG.data_path)\n",
    "    # Reshuffle with the new seed for different training order\n",
    "    training_data_df = training_data_df.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "    print(f\"Training dataset size: {len(training_data_df)}\")\n",
    "\n",
    "    test_df = pd.read_csv(f\"{CFG.data_path}/test.csv\")\n",
    "    \n",
    "    # Apply URL semantic extraction (from Experiment 7)\n",
    "    training_data_df['body_with_url'] = training_data_df['body'].apply(lambda x: x + url_to_semantics(x))\n",
    "    training_data_df['input_text'] = training_data_df['rule'] + \"[SEP]\" + training_data_df['body_with_url']\n",
    "\n",
    "    # Tokenize\n",
    "    tokenizer = AutoTokenizer.from_pretrained(CFG.model_name_or_path)\n",
    "    train_encodings = tokenizer(\n",
    "        training_data_df['input_text'].tolist(), \n",
    "        truncation=True, \n",
    "        padding=True, \n",
    "        max_length=CFG.MAX_LENGTH\n",
    "    )\n",
    "    train_labels = training_data_df['rule_violation'].tolist()\n",
    "    train_dataset = JigsawDataset(train_encodings, train_labels)\n",
    "\n",
    "    # Load model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(CFG.model_name_or_path, num_labels=2)\n",
    "    \n",
    "    # Training arguments (Experiment 7's proven config)\n",
    "    output_dir = f\"./deberta_seed_{seed}\"\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=CFG.EPOCHS,\n",
    "        learning_rate=CFG.LEARNING_RATE,\n",
    "        per_device_train_batch_size=CFG.BATCH_SIZE,\n",
    "        warmup_ratio=0.1,\n",
    "        weight_decay=0.01,\n",
    "        report_to=\"none\",\n",
    "        save_strategy=\"no\",\n",
    "        logging_steps=100,\n",
    "        seed=seed,\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    print(f\"\\nStarting training with seed {seed}...\")\n",
    "    trainer.train()\n",
    "    print(f\"Training complete for seed {seed}!\\n\")\n",
    "\n",
    "    # Generate predictions\n",
    "    print(f\"Generating predictions for seed {seed}...\")\n",
    "    test_df['body_with_url'] = test_df['body'].apply(lambda x: x + url_to_semantics(x))\n",
    "    test_df['input_text'] = test_df['rule'] + \"[SEP]\" + test_df['body_with_url']\n",
    "    \n",
    "    test_encodings = tokenizer(\n",
    "        test_df['input_text'].tolist(), \n",
    "        truncation=True, \n",
    "        padding=True, \n",
    "        max_length=CFG.MAX_LENGTH\n",
    "    )\n",
    "    test_dataset = JigsawDataset(test_encodings)\n",
    "    \n",
    "    predictions = trainer.predict(test_dataset)\n",
    "    probs = torch.nn.functional.softmax(torch.tensor(predictions.predictions), dim=1)[:, 1].numpy()\n",
    "\n",
    "    submission_df = pd.DataFrame({\n",
    "        \"row_id\": test_df[\"row_id\"],\n",
    "        \"rule_violation\": probs\n",
    "    })\n",
    "    \n",
    "    output_file = f\"submission_{output_suffix}.csv\"\n",
    "    submission_df.to_csv(output_file, index=False)\n",
    "    print(f\"Saved predictions to: {output_file}\\n\")\n",
    "    \n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with Seed 42 (Experiment 7 Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_42 = train_and_predict(seed=42, output_suffix=\"seed42\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with Seed 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_123 = train_and_predict(seed=123, output_suffix=\"seed123\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with Seed 456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_456 = train_and_predict(seed=456, output_suffix=\"seed456\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble the Three Models with Equal Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Creating Ensemble from 3 Seeds\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Rank normalization\n",
    "def rank_normalize(series):\n",
    "    return series.rank(method='average') / (len(series) + 1)\n",
    "\n",
    "r1 = rank_normalize(pred_42['rule_violation'])\n",
    "r2 = rank_normalize(pred_123['rule_violation'])\n",
    "r3 = rank_normalize(pred_456['rule_violation'])\n",
    "\n",
    "# Equal weight ensemble (no tuning needed)\n",
    "ensemble = (r1 + r2 + r3) / 3.0\n",
    "\n",
    "print(f\"Ensemble Statistics:\")\n",
    "print(f\"  Mean: {ensemble.mean():.4f}\")\n",
    "print(f\"  Std:  {ensemble.std():.4f}\")\n",
    "print(f\"  Min:  {ensemble.min():.4f}\")\n",
    "print(f\"  Max:  {ensemble.max():.4f}\")\n",
    "\n",
    "# Measure prediction diversity (variance across seeds)\n",
    "variance = np.var([r1, r2, r3], axis=0).mean()\n",
    "print(f\"\\nPrediction Diversity:\")\n",
    "print(f\"  Average variance across seeds: {variance:.6f}\")\n",
    "print(f\"  (Higher = more diversity = better ensemble potential)\")\n",
    "\n",
    "# Create final submission\n",
    "submission = pd.DataFrame({\n",
    "    'row_id': pred_42['row_id'],\n",
    "    'rule_violation': ensemble\n",
    "})\n",
    "\n",
    "submission.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Submission Created\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Saved to: /kaggle/working/submission.csv\")\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "print(submission.head(10))\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Expected Performance\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Target: 0.918-0.919 AUC\")\n",
    "print(f\"Rationale: Seed diversity reduces variance without adding complexity\")\n",
    "print(f\"Risk Level: Very Low (same proven config from Exp 7, just repeated)\")\n",
    "print(f\"\\nStrategy: Simplicity + Diversity = Better Performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What We Did:\n",
    "- Used Experiment 7's exact proven configuration (3 epochs, LR=2e-5, MAX_LENGTH=512)\n",
    "- Trained DeBERTa v3 three times with seeds: 42, 123, 456\n",
    "- Ensembled with equal weights (1/3 each)\n",
    "\n",
    "### Why This Works:\n",
    "1. **Proven base**: Experiment 7 scored 0.917 with seed 42\n",
    "2. **Variance reduction**: Different seeds → different local optima → more robust\n",
    "3. **No added complexity**: Same training, no over-optimization\n",
    "4. **Training-time TTA**: Like test-time augmentation but at model level\n",
    "\n",
    "### Key Lesson:\n",
    "**Sometimes the best improvement isn't adding complexity, it's adding diversity to what already works.**\n",
    "\n",
    "### Expected Result:\n",
    "- Target: 0.918-0.919 AUC (small but consistent improvement)\n",
    "- This approach is very safe and should not hurt performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
